---
layout: default
---

# 嵌入式AI简报 (2020-08-26)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：本

好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：

- 英伟达最快月底收购ARM，估值或达500亿美元
新智元
https://mp.weixin.qq.com/s/ua9Sn5ZxzzrB1tsmpIbiwg
400亿英镑，芯片史上最大一笔并购案预计今年夏末完成！据外媒报道，美国芯片巨头英伟达收购软银集团旗下英国芯片设计公司Arm的谈判正在加快，双方已进入排他性谈判阶段。
在8月初的报道中就提出，这次交易或将是芯片行业史上最大的一笔收购案。  
- AI推理性能最高提升20倍，IBM首款7nm商用处理器POWER10面世
机器之心
https://mp.weixin.qq.com/s/H8uhmdRG5xqwcXdrtFO-mA
今年的 Hot Chips 2020 会议上，IBM 正式宣布了新一代 CPU POWER10。作为 Power 9 的继任者，POWER10 的处理效率是前者的三倍，同时又提供了更高的工作负载量和容器密度。
这是 IBM 的首款商用 7 nm 处理器，三星的 7nm EUV 制程微缩使得 IBM 可以添加更多的核心和更多的缓存。
每个芯片具有 15 个活跃的 CPU 核，其中管芯上还有一个用于提升成品率的备用核。此外，每个 CPU 可以支持 8 个线程（虚拟 CPU），所以每个插槽中共计有 120 个线程。
管芯上缓存内存总量为 150MB 以上。在接口设置上，下一代 PCI Express Gen 5 具有 64 条通路，传输速度高达 32GT/s。
考虑到 AI 越来越重要，IBM 增加了对其他指令和数据类型的支持。处理器通过新的可扩展指令集支持 Power 的 3.1 版本。POWER10 也意味着 IBM 更加重视 CPU 中的 AI 推理性能。

IBM 表示，推理处理中使用的矩阵数学函数可将性能提升 10-20 倍。缓存带宽上也有改进，以使 SIMD 单元获得数据。

IBM 也放弃了英伟达的 NVLink 接口，因为 PCIe v5 提供了足够的带宽。

- RIOS国际开源实验室（RISC-V International OpenSource Laboratory）与Imagination Technologies建立战略伙伴关系，共同助力RISC-V生态发展



> 注：个别链接打不开，请点击文末【阅读原文】跳转

## 业界新闻

- [美国断掉华为芯片后路：买第三方芯片也不行，华为云等38家子公司也进入“实体清单” | 量子位](https://mp.weixin.qq.com/s/58_LX6cyuhbKFfHSms2Njw)  
摘要：华为临时许可过期之后，美国商务部再发最新声明，进一步收紧对华为的限制。其目的很明确：打击华为获取商用芯片。就是说，在5月15日强制台积电120天后“断供”华为，导致华为麒麟芯片难以为继之后，美国现在又要“封杀”华为采购第三方设计芯片的路径了。  
此前，据台湾媒体《财讯快报》报道，半导体业界消息称，华为已与联发科签订合作意向书与采购大单，且订购芯片数量超过1.2亿颗。  
- [末代麒麟高端芯！华为Mate 40 Pro盖板曝光：外形敲定 | 安兔兔](https://mp.weixin.qq.com/s/eZviNoZwA-XZlHrM4AUoKw)  
摘要：麒麟9000将采用台积电5nm工艺打造，CPU采用A77架构、GPU为Mali G77，性能相比上代进一步提升，同时拥有更强大的5G能力和AI处理能力。  
- [苹果A14有多强？竞品是英特尔酷睿i9 | 安兔兔](https://mp.weixin.qq.com/s/xamgu9JKh3n283jqGaYvKw)  
摘要：A14X Bionic芯片将首发于下一代iPad Pro产品上，而它的性能也将获得史无前例的大幅度提升，称其性能几乎可以与英特尔酷睿i9-9880H相当。  
手机方面的话，今年9月的iPhone 12系列5G手机，预计会有四款，将采用A14 Bionic芯片，用上台积电5nm工艺，它的性能相比前代提升约50%，而苹果也宣布了将逐步从英特尔的芯片过渡到自研A系列芯片的消息，所以今后iPhone和iPad的对比对象都会是移动笔记本平台的芯片产品了。  
- [骁龙860/骁龙875 Lite曝光 真正的高通次旗舰5G芯片 | 安兔兔](https://mp.weixin.qq.com/s/knW2QFzDepYTiXjXGHn5NQ)  
摘要：有消息称，高通正在规划属于骁龙800系列家族的次旗舰5G芯片，填补骁龙800系列、骁龙700系列之间的空白，更好地应对华为麒麟800系列、天玑800系列等竞品。至于具体是什么产品，据说暂定名为骁龙860，也就是骁龙865稍作精简，当然也是外挂5G基带。  
而到了下一代，高通有望在年底按惯例推出新旗舰，命名为骁龙875G，首次在旗舰平台集成5G基带，而它也会有一个精简版，可能叫做骁龙875 Lite。  
根据此前曝光的路线图，高通将在今年第四季度商用骁龙662、骁龙460，明年第一季度商用骁龙875G、骁龙435G，明年第二季度商用骁龙735G。其中，骁龙875G、骁龙735G采用三星最新的8nm工艺制造，但据称该工艺目前良品率还不达标，可能会影响高通的计划。  
- [PC的CPU“大小核”将至，或将拉开新时代的序幕 | 三易生活](https://mp.weixin.qq.com/s/I_vrm_ZIKJfU335mGRa-EQ)  
摘要：PC CPU的“大小核”时代快要来了。  
根据Intel官方产品库（Intel ARK）公布的信息显示，Core i5-L16G7属于全新的“Lakefield”家族。它的CPU部分采用了一颗Sunny Cove大核心（和IceLake近似）和四颗Tremont小核心（此前用在服务器级别的Atom P5000系列上），主频为1.40GHz至3GHz。  
2020年8月初，一份关于Intel第12代酷睿处理器家族AlderLake详细规格的文档遭到披露，其中清楚的显示，AlderLake系列中除了极少数型号之外，绝大多数SKU的CPU部分均由“Golden Cove”新架构大核心与“Gracemont”新架构小核心共同组成“big·SAMLL”的大小核设计。其中既有8大核8小核的旗舰型号，也会有2大核8小核的入门款“十核”。  
AMD的一份专利信息也被曝光，显示它们同样也在研究“大小核”CPU设计方案。而且在这份专利中还明确提到了大小核之间转移任务时，需要判断当前进程是否分别兼容大核与小核的指令集。而这则基本上明示了AMD的“大小核”设计理念会与Intel一样，采用架构、指令集、性能都差异较大的两种CPU核心设计高低搭配。  
控制成本、简化编程，是“大小核”背后的需求。虽然目前的初代“大小核”PC处理器说实在的性能或许还有些不济，但大家要看到，它们的功耗实际上已经只比当下功耗最高的手机SoC高不到1W了。随着未来PC CPU厂商继续技术深耕，保不齐哪天x86架构的“大小核”处理器在能效比上就真有可能压倒如今越来越臃肿的ARM移动芯片。   


## 论文


- [美国东北大学等提出新型剪枝方案，全自动实时移动端AI框架：YOLO-v4目标检测、换脸、视频上色全部实时手机端实现 | 极市平台](https://mp.weixin.qq.com/s/EGqim7gw3N8gt9HTIoGiAw)  
摘要：研究人员可视化了 VGG-16 在 ImageNet 上的预训练模型的部分权重，并且发现（i）卷积核的有效面积（即具有较高绝对值的权重）形成一些特定形状并在模型中反复出现，（ii）某些卷积核的权重值非常小，因此并不能对输出产生有效的激活，研究人员认为这种卷积核是无效卷积核。基于上述两个发现，该研究提出了一个新的稀疏性维度——模式化稀疏度，并且提出了基于模式化稀疏度的深度神经网络权重模式化剪枝的概念。  
研究者在算法实现层面，设计了模式化稀疏度感知训练框架（pattern-aware network pruning framework），能够同时实现卷积核模式集的自动提取，模式化稀疏度的自动选择与模型训练。在卷积核模式集的自动提取中，研究人员首先构建一个模式集全集，包含了所有可能种类的卷积核模式。在训练过程中，他们将这个模式集作为稀疏化目标，通过 ADMM（alternating direction method of multipliers）将原始剪枝问题解耦为 Primal-Proximal 问题，迭代式地通过传统梯度下降法求解 Primal 问题，并引入一个二次项迭代求解 Proximal 问题。通过每次 Primal-Proximal 迭代更新，使卷积核动态地从模式集中选择当前最优的卷积核模式，并同时通过梯度下降法训练该模式非零位置的权重。当卷积核对稀疏模式的选择趋于稳定的时候（一般仅需要迭代 3-5 次），就可以删除掉那些被选择次数非常少的卷积核模式，从而将模式集的大小降低，并用更新后的模式集进行下一轮迭代，最终实现模式集的自动提取。  
研究人员首先确定了每一个卷积核中应保留 4 个非零值，这样做的好处是控制模式集总集的大小，同时也利于移动端 CPU/GPU 的 SIMD 结构，并在 ImageNet 图像上的推理速度与在现有的深度神经网络加速器（TVM、MNN、TensorFlow-Lite）上做了速度对比。  
- [OverNet | 速度快&高性能&任意尺度超分 | AIWalker](https://mp.weixin.qq.com/s/sFWdZZrZY_5USF_bbyQZFA)  
摘要：基于CNN的超分方法往往存在计算量过大的问题，同时大多模型仅能处理特定超分比例，进而导致泛化性能缺失，提升了内存占用需求(注：这里指的是模型部署过程中的模型大小)。为解决上述局限性，作者提出了OverNet，一种轻量型CNN网络用于单模型任意尺度图像超分。首先，作者引入一种轻量型递归特征提取器，它通过跳过链接、稠密连接进行特征的重复与有效应用；然而，为最大化特征提取器的性能，作者提出了一种高精度重建模块，它可以轻易嵌入到现有超分网络中并改进性能；最后，作者引入多尺度损失函数并获得了跨尺度泛化性能。  
作者通过实验验证了所提方法的优异性能，具有更少的参数量、更优的性能。该文的主要贡献包含以下几点：一种轻量型递归特征提取器；一种过尺度模块用于生成过尺度特征并进而用于生成任意尺度输出，它可以有效提升模型的重建效果；一种新颖的多尺度损失函数，它可以同时进行单模型多尺度训练。  
- [ANTNet | 端侧架构，精度速度双超MobileNetV2 | AIWalker](https://mp.weixin.qq.com/s/fauHZ-kcYnYQdzwLnbI3Sg)  
摘要：
paper: https://arxiv.org/abs/1904.03775
code: https://github.com/yyxiongzju/ANTNets
尽管深度分离卷积是一种比标准卷积更有效的计算单元，但它往往会导致模型的表达能力降低。基于资源负载约束(比如计算消耗和参数量)，作者提出一种新颖的模块ANTBlock。通过在ANTBlock中引入注意力机制(位于depthwise卷积与投影层之间，与MobileNetV3类似)，它可以在高维空间提升模型的表达能力。  
作者通过实验表明：基于ANTBlock构建的ANTNet可以跨数据集取得更优的性能(相比同等计算消耗的端侧网络架构，比如MobileNet与ShuffleNet系列)。在CIFAR100数据集上，所提方法取得了75.7%的top1精度，它比MobileNetV2高1.5%且少8.3%的参数量与19.6%的计算量；在ImageNet数据集上，所提方法取得了72.8%的top1精度，它比MobileNetV2高0.8%，同时在iphone5上的速度为157.7ms(比MobileNetV2快20%)。


## 开源项目

> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [PaddlePaddle/PaddleOCR: 百度PaddleOCR再发大招：自研顶会SOTA算法正式开源 | 飞桨PaddlePaddle](https://mp.weixin.qq.com/s/H_etZDJjfx1t2FaIJ7gGdA)  
摘要：首先，简单对比一下目前主流OCR方向开源repo的核心能力：  
    - 对于语种方面，easyOCR的优势在于多语言支持，非常适合有小语种需求的开发者；
    - 从预训练模型来看，easyOCR目前暂无超轻量模型，chineseocr_lite最新的模型是10M左右，而PaddleOCR提供的8.6M是目前业界已知最轻量的； 
    - 对于部署方面，easyOCR模型较大不适合端侧部署，Chineseocr_lite和PaddleOCR都具备端侧部署能力；  
    - 对于自定义训练，实际业务场景中，预训练模型往往不能满足需求，对于自定义训练和模型Finetuning，目前只有PaddleOCR支持。  
PaddleOCR 8.6M超轻量模型，支持自定义训练、丰富的部署方式（覆盖服务器端、移动端/嵌入式端（apk/sdk）多场景需求）。  
- [karpathy/minGPT: 特斯拉AI总监Karpathy写了个GPT的Pytorch训练库，仅300行代码 | 机器之心](https://mp.weixin.qq.com/s/aPA0PEqVn509u3xbgmhIwQ)  
摘要：
minGPT 项目地址：https://github.com/karpathy/minGPT
近日，特斯拉人工智能研究负责人、前 OpenAI 研究科学家 Andrej Karpathy 进行了尝试。

他基于 PyTorch，仅用 300 行左右的代码就写出了一个小型 GPT 训练库，并将其命名为 minGPT。





Karpathy 表示，这个 minGPT 能够进行加法运算和字符级的语言建模，而且准确率还不错。 

## 博文

- [基于NCNN的3x3可分离卷积再思考盒子滤波 | GiantPandaCV](https://mp.weixin.qq.com/s/bfxbRtdviPuXM4MJc_AyAQ)  
摘要：这篇文章主要是对NCNN 的3x3可分离卷积的armv7架构的实现进行了非常详细的解析和理解，然后将其应用于盒子滤波，并获得了最近关于盒子滤波的优化实验的最快速度（截至到目前，并不代表一定是最快的），希望对做工程部署或者算法优化的读者有一定启发。  
- [AI基准测试MLPerf模型少、更新慢，地平线提出的MAPS会更好吗？ | CCF-GAIR 2020](https://mp.weixin.qq.com/s/GhoekBz_IU5UrcpmcvVUxw)  
摘要：地平线联合创始人兼技术副总裁黄畅指出：MLPerf有模型更新慢、模型少、模型选择受各种因素影响的挑战。他也首次提出了新的方法用以评估芯片的AI真实性能——MAPS (Mean Accuracy-guaranteed Processing Speed，在精度有保障范围内的平均处理速度)。  
MAPS是评估AI芯片真实性能更好的方法吗？AI芯片性能的评估需要快、准、省，在这三个维度下地平线提出的新的AI芯片性能评估的方法称为MAPS（Mean Accuracy-guaranteed processing speed），意思是在精度有保障的范围评测芯片的平均效能，得到一个全面、完整、客观、真实的评估。  
MAPS的计算公式：MAPS = 所围面积 /（最高精度-最低精度），含义为在 ImageNet 的主流精度范围（75%~80%）下，速度最快的模型所代表的点（由精度和帧率确定）所围多边形面积大小即为芯片处理ImageNet AI任务的能力大小。
其代表的真实的AI效能也有对应的公式：`MAPS/Watt & MAPS/＄=TOPS/ Watt & TOPS/＄ X Utilization X MAPS/TOPS`。这三个要素中，第一个TOPS/Watt、TOPS/$是传统的方式。中间的要素有效利用率，是根据架构特点，利用编译器等去统化地解决极其复杂的带约束的离散优化问题，得到一个算法在芯片上运行的实际的利用率，实际是软硬件计算架构的优化目标。第三个要素是AI算法效率，指的是每消耗一个TOPS算力，带来的实际AI算法性能，体现的是AI算法效率的持续提升。  
- [如何利用 NVIDIA 安培架构 GPU 的新一代 Tensor Core 对计算进行极致加速 | NVIDIA开发者社区](https://mp.weixin.qq.com/s/DE7HyoUUUNSiBXczkJLsAg)  
摘要：2020年5月14日，NVIDIA发布了最新的 GPU 架构:安培，以及基于安培架构最新的 GPU A100。在安培架构中新增了功能强大的第三代 Tensor Core 单元。相较于 V100，A100 上搭载的第三代 Tensor Core 增加了对 DL （Deep Learning）和 HPC （High Performance Computing） 数据类型的全面支持，提高了各精度的运算吞吐能力，同时新增了稀疏运算特性，进一步实现了峰值运算性能的翻倍。  
本文将会回顾一下 Tensor Core 的发展路线，并介绍如何通过 inline PTX 使用 Tensor Core如mma PTX 指令还有ldmatrix PTX 指令等等。  
- [AI训练芯片巅峰对决，如何正确“围观” | StarryHeavensAbove](https://mp.weixin.qq.com/s/iipdabuVjesHJ6w9OecgNg)  
摘要：AI芯片Benchmark MLPerf最近公开了训练测试0.7版本的结果。这次的结果有以下几个主要看点和亮点：
新硬件亮相：Google TPU4应该算第一次公开亮相，Nvidia A10，华为的Ascend910第一次参与。此外，这次Nvidia的A100和Google TPUv4系统，CPU则来自AMD。
训练系统的规模继续飙升：Google TPU v3系统最多4096个处理器，TPU v4系统最多256个处理器；Nvidia V100系统最多1536个处理器，A100系统最多2048个处理器；中国科学院深圳先进技术研究院提交的Ascend910系统最多1024个处理器。
自有框架和硬件相结合：Framework方面，Nvidia针对推荐系统的Merlin/HugeCTR，Google的JAX和华为的Mindspore都是第一次亮相。这几个框架和Tensorflow，Pytorch相比都针对自家硬件有更多性能的优化。



> 注：个别链接打不开，请点击文末【阅读原文】跳转



## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)


| 2 | 0 | 2 | 0 |
|:---:|:---:|:---:|:---:|
| - | [2020-08-06](../embedded-ai-report/2020-08-06.md) | [2020-07-18](../embedded-ai-report/2020-07-18.md) | [2020-07-02](../embedded-ai-report/2020-07-02.md) |
| [2020-06-17](../embedded-ai-report/2020-06-17.md) | [2020-06-03](../embedded-ai-report/2020-06-03.md)  | [2020-05-15](../embedded-ai-report/2020-05-15.md) | [2020-04-26](../embedded-ai-report/2020-04-26.md) |  
| [2020-04-04](../embedded-ai-report/2020-04-04.md) | [2020-03-19](../embedded-ai-report/2020-03-19.md) | [2020-03-02](../embedded-ai-report/2020-03-02.md) | [2020-02-16](../embedded-ai-report/2020-02-16.md) |  
| [2020-01-27](../embedded-ai-report/2020-01-27.md) | [2020-01-06](../embedded-ai-report/2020-01-06.md) | [2019-12-17](../embedded-ai-report/2019-12-17.md)  |  [2019-12-02](../embedded-ai-report/2019-12-02.md) |
| 2 | 0 | 1 | 9 |  
| [2019-11-30](../embedded-ai-report/2019-11-30.md) | [2019-11-18](../embedded-ai-report/2019-11-18.md) | [2019-10-31](../embedded-ai-report/2019-10-31.md)  |  [2019-10-17](../embedded-ai-report/2019-10-17.md) |  
| [2019-10-03](../embedded-ai-report/2019-10-03.md) | [2019-09-16](../embedded-ai-report/2019-09-16.md) | [2019-08-30](../embedded-ai-report/2019-08-30.md)  |  [2019-08-15](../embedded-ai-report/2019-08-15.md) |  
| [2019-07-30](../embedded-ai-report/2019-07-30.md) | [2019-07-15](../embedded-ai-report/2019-07-15.md) | [2019-06-29](../embedded-ai-report/2019-06-29.md)  |  [2019-06-17](../embedded-ai-report/2019-06-17.md) |  
| [2019-05-30](../embedded-ai-report/2019-05-30.md) | [2019-05-15](../embedded-ai-report/2019-05-15.md) | [2019-04-27](../embedded-ai-report/2019-04-27.md)  |  [2019-04-13](../embedded-ai-report/2019-04-13.md) |  
| [2019-03-31](../embedded-ai-report/2019-03-31.md) | | |  

----

![wechat_qrcode](../wechat_qrcode.jpg)

> 往期回顾：见公众号主菜单【历史消息】
- WeChat: NeuralTalk  
- Editor: https://github.com/ysh329  
- Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
