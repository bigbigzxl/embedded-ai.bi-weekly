---
layout: default
---

# 嵌入式AI简报 (2020-10-21)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：本次xx条。「新闻」；「论文」；「开源」；「博文」。



好了，先是一些热身小新闻ヽ(✿゜▽゜)ノ：

- Imagination Technologies宣布推出全新IMG B系列GPU IP。其第一个包含新多核架构的GPU IP系列，峰值算力达6 TFLOPS，AI算力可达24 TOPS，其汽车GPU已符合ISO 26262安全标准要求，并支持自动驾驶和辅助驾驶；


-
> 注：个别链接打不开，请点击文末【阅读原文】跳转


## 业界新闻  


- [安谋中国“周易”Z2 AIPU正式发布，性能翻倍、效率翻番 | Arm中国](https://mp.weixin.qq.com/s/K1mFIbXkptioQtv96Q_M9Q)  
摘要：安谋科技正式发布“周易”Z2 AIPU（AI Processing Unit），单核算力最高可达4TOPS，较“周易”Z1 AIPU的单核算力提高一倍，同时支持多达32核的可扩展配置，从而能够在单个SoC中实现128TOPS的强大算力。  
“周易”Z2 AIPU延用了“周易”AIPU的架构，并在微架构上优化，将芯片面积减少30%，在运行部分神经网络模型时，相同算力配置下性能提升可达100%。此外，“周易”Z2 AIPU对内存子系统做了优化，并升级高级带宽节省技术（Advanced Bandwidth Saving Technology，ABST），除了第一代中已有的权重压缩（weight compression）技，还有feature map压缩。全新“周易”Z2 AIPU将主要面向中高端安防、智能座舱和ADAS、边缘服务器等应用场景。  
在软件框架之上，通过Arm Compute Library或者合作伙伴的异构计算库，支持Arm NN、安卓NN等多种流行接口。“周易”AIPU也支持TensorFlow、ONNX等，未来也将支持更多不同的扩展框架。  
- [ARM揭晓未来两代CPU大核架构Matterhorn和和Makalu：性能大增 | 安兔兔](https://mp.weixin.qq.com/s/KCEIu0lgHLr8VrUvlBEqYA)  
摘要：ARM举办了DevSummit开发者峰会，ARM预览了未来两代的Cortex CPU大核，分别代号Matterhorn（马特洪峰，是阿尔卑斯山脉最为人所知的山峰）和Makalu（马卡鲁峰，海拔8463米）。  
峰值性能方面，2022年的Makalu预计将比Cortex-A78提升30%。注意，这里的Cortex A78性能基数是5nm、3GHz频率的参考芯片。  
- [5nm打造 Exynos 1080宣布：首发厂商vivo今年Q4上市 | 安兔兔](https://mp.weixin.qq.com/s/N8yIjphWYOIG9IdENMwGRw)  
摘要：Exynos 1080外界猜测是和骁龙875一样的5nm LPE工艺，能效比进一步提升。其采用了ARM最新的CPU架构Cortex-A78，以及最新的GPU架构Mali-G78。  
从规格参数来看，Exynos 1080达到了旗舰级水平，而且号称是专门针对中国市场设计。据ARM官方数据显示，在同等工艺条件下，A78的CPU性能相比A77提升了20%左右，G78的GPU性能相比G77提升25%。  
另外，据说还有一款定位更高的5nm旗舰三星芯片，命名为Exynos 2100，将会首发于三星自家机型。  
- [高通5nm骁龙875曝光：首次用上超大核 | 安兔兔](https://mp.weixin.qq.com/s/r2qo7wEkWn9Pyvrtmwqpnw)  
摘要：高通5nm旗舰处理器骁龙875将首次采用Cortex X1超大核心。采用“1+3+4”八核心设计，其中“1”为超大核心Cortex X1。  
以往高通骁龙旗舰处理器也采用过“1+3+4”这种“超大核+大核+能效核心”这样的三丛集八核心架构，但是超大核和大核之间的差别主要在于CPU频率。以高通骁龙865为例，它的超大核为2.84GHz，大核心为2.42GHz，超大核和大核均为Cortex A7。  
这次高通骁龙875将首次采用Cortex X1超大核+Cortex A78大核这样的组合，其中Cortex X1的峰值性能比Cortex A78高23%，堪称真正意义上的“超大核”。  
- [高通7系5G新U发布！A77架构、小米首发搭载 | 安兔兔](https://mp.weixin.qq.com/s/sI1q0Yl9FA4kHSJrdwgDMg)  
摘要：高通正式发布了全新7系骁龙处理器，命名为骁龙750G 5G，代号为SM7225，定位中端。  
规格方面，骁龙750G基于8nm工艺打造，CPU为八核心设计，由两个频率为2.2GHz的A77大核和六个1.8GHz的A55组成，GPU集成Adreno 619。  
从参数来看，该处理器似乎是骁龙690的提频版，但相比骁龙730G的性能在CPU和GPU都有着提升，骁龙750G采用了Kryo 570 CPU，相较于骁龙730G的Kryo 470提高了20%、图形渲染性能提高了10%（相比730G的Adreno 618）。理论数据来看，骁龙750G在GPU方面略低于骁龙768G/765G的Adreno 620。  
搭载骁龙750G的商用终端预计将于2020年底面市，由小米首发。  
- [骁龙775G曝光！6nm工艺打造、性能超8系旗舰 | 安兔兔](https://mp.weixin.qq.com/s/HE_DvOXgcNg7Ug-NXRny9A)  
摘要：即将发布的骁龙875的代号为SM8350，内部称为Lahaina（地名，位于夏威夷群岛），而且提供了Plus版本。  
骁龙875采用三星5nm EUV工艺打造，拿7nm EUV工艺对比，前者性能提升10%，功耗降低了20%，逻辑面积效率提升25%，据说骁龙875的超大核基于Cotex-X1打造。
与此同时，骁龙775G，代号为SM7350，内部称为Cedros，亮相时间可能在明年初。据悉，骁龙775G采用6nm工艺打造，相比骁龙765G升级很大，公版测试平台的配置是12GB LPDDR5 RAM、256GB UFS 3.1 ROM、120Hz屏。
骁龙775G的定位次旗舰，和骁龙765G相比，CPU性能提升40%、GPU性能则增幅50%。775G表现超过了骁龙855，拭目以待。


## 论文


- [2009.07453v2] [Extremely Low Bit Transformer Quantization for On-Device Neural Machine Translation](https://arxiv.org/abs/2009.07453v2)  
链接：https://arxiv.org/abs/2009.07453v2  
摘要：移动设备或边缘设备在Transformer架构的推理上显得力不从心，但量化是解决这些挑战的有效技术之一。作者分析表明对给定的量化比特数，每个Transform block对翻译质量和推理计算的贡献是不同的。此外，即使在embedding block中，每个单词也呈现出极大的不同贡献。  
因此，作者提出混合精度量化策略，以极低的比特数（例如，低于3比特）来表示Transform权重。例如，对于embedding block中的每个字，根据统计特性分配不同的量化比特。作者的量化Transform模型比基线模型小11.8倍，BLEU小于-0.5bleu，运行时内存减少了8.3倍，速度提高了3.5倍（Galaxy N10+）。  
- [2010.02871v1] [LETI: Latency Estimation Tool and Investigation of Neural Networks inference on Mobile GPU](https://arxiv.org/abs/2010.02871v1)  
链接：https://arxiv.org/abs/2010.02871v1  
摘要：在移动设备上运行推理，其准确度和推理时间对许多问题都有意义。虽然常拿flop的数量作为神经网络耗时的基础评估，但它与实际运行推理的耗时相差甚远。为了获得更精确的推理耗时，研究界使用所有可能层的查找表来计算延迟，最终预测移动CPU上的推理。遗憾的是，在移动GPU上，这种方法并不适用，且不准确。  
作者在这项工作中，将移动GPU上的延迟近似视为一个数据和硬件特定的问题。主要目标是建立一个估计工具，用于神经网络推理的研究，并为每一个特定的任务建立一个稳健和准确的预测模型。为了实现这一目标，我们构建了开源工具，为在不同的目标设备上以移动GPU为核心进行大规模实验提供了一种方便的途径。在对数据集评估后，作者建立了实验数据的回归模型，并将其用于未来的延迟预测和分析。实验证明了这种方法在NAS基准101数据集子集上的有效性，并对两个移动gpu在常见的网络结构做了性能评估。  
- [2010.07185v1] [Effective Algorithm-Accelerator Co-design for AI Solutions on Edge Devices](https://arxiv.org/abs/2010.07185v1)  
链接：https://arxiv.org/abs/2010.07185v1  
摘要：高质量的人工智能解决方案需要人工智能算法和硬件的联合优化，如模型及其硬件加速器。为了提高整体方案的质量和设计效率，有效的算法和加速器协同设计方法是必不可少的。  
本文首先讨论了算法/加速器协同设计问题的动机和挑战，然后给出了几种有效的解决方案。重点介绍了有效协同设计方法的三个主要工作：1）第一个同步的DNN/FPGA协同设计方法；2）一种双向的轻量级DNN与加速器协同设计方法；3）一种可微且高效的DNN与加速器协同搜索方法。  
作者在FPGA和GPU上进行了大量的实验，并与现有的工作进行了比较，证明了所提出的协同设计方法的有效性。本文强调了算法加速器协同设计的重要性和有效性，并呼吁在这一有趣且要求更高的领域取得更多的研究突破。  


## 开源项目


> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [tensorflow/models:谷歌推出新模型「pQRNN」，少量参数下进行文本分类，性能堪比BERT | 新智元](https://mp.weixin.qq.com/s/GGElvaSYwcZGbkKtB0AL4g)  
链接：https://github.com/tensorflow/models/tree/master/research/sequence_projection  
摘要：近日，谷歌推出了新模型「pQRNN」，它是由去年推出的「PRADO」进一步使用小模型改进而得，达到了SOTA结果。pQRNN的新颖之处在于，它可以结合一个简单的映射和一个quasi-RNN编码器来进行快速并行处理。同时，谷歌证明了该模型能在参数较少的情况下进行文本分类任务，并达到BERT级别的性能表现。  
通过使用上一代模型PRADO证明了它可以作为下一代最先进的轻量级文本分类模型的基础。改进后的pQRNN模型表明这种新的体系结构几乎可以达到BERT级的性能，尽管只使用1/300的参数量和有监督的数据。  
- [tensorflow/tfjs：SIMD 和多线程大幅增强 TFJS WebAssembly 后端 | TensorFlow](https://mp.weixin.qq.com/s/ztyeCYZtwcvp7MJgsVt82w)  
摘要：3 月，TensorFlow.js 推出了一个新的 WebAssembly (Wasm) 加速后端（继续阅读以进一步了解 Wasm 及其重要性）。  
近日宣布一项重大性能更新：自 TensorFlow.js 版本 2.3.0 起，Wasm 后端将利用 SIMD（向量）指令和 XNNPACK（一种高度优化的神经网络算子库）多线程实现 10 倍提速。  
- [mindspore/mindspore：华为MindSpore 1.0版本正式发布 | MindSpore](https://mp.weixin.qq.com/s/aDJQUlPspAohUYbHwiVzFw)  
摘要：1.0版本汇总了先前的主要功能特色，第一是二阶优化算法，MindSpore自研二阶优化算法THOR通过减少二阶矩阵求逆次数以及降低二阶矩阵的维度来降低求逆时间，在Bert-Large上，使用MLPerf测试集，达到71.2%精度仅需3000step，端到端训练时间为14min，极大的提升了模型的训练速度。  
第二是图算融合优化，对原有计算逻辑进行拆分、重组、融合等操作，以减少算子执行间隙的开销并且提升设备计算资源利用率，
该特性中，所有优化项均自动完成，无需网络DSL感知。同时基于polyhedral技术实现融合算子编译，带来更加通用、高性能的算子融合能力。最后提供了自定义算子表达能力，更易用，更高性能。  
第三是发布轻量级神经网络推理框架MindSpore Lite，帮助开发者使能端侧及边缘侧AI能力。主要包含离线转换工具和轻量级运行时两部分。  

【【【【oneflow】】】】

## 博文

- [高通Cloud AI 100芯片：模糊边缘与数据中心，看见了AI芯片的“多面” | 量子位](https://mp.weixin.qq.com/s/Mo1UiTwAW-TRJ92DjTOSgQ)  
摘要：2019年4月，高通宣布推出Cloud AI 100芯片，称它是“为满足急剧增长的云端AI推理处理的需求而设计”、“让分布式智能可以从云端遍布至用户的边缘终端，以及云端和边缘终端之间的全部节点。”  
即使是英伟达最新Ampere架构的A100芯片，吞吐量也不到25000，耗能却超过了300W。从功耗来看，英特尔的Goya可低达100W，但吞吐量只能达到15000左右。相比之下，高通的Cloud AI 100 PCle，吞吐量超过25000，却只需要75W，其支持最高每秒400万亿次（400TOPS）的算力。
内部结构上，16个AI内核（AIC），支持INT8，INT16，FP16和FP32，4个64位内存控制器（LPDDR4×），144MB的片上SRAM高速缓存。也就是说，通道的总系统带宽为134GB/s，但144MB的片上SRAM高速缓存设计，在片上保存了尽可能多的存储器流量。此外，7nm的工艺节点，也有助于降低功耗。在封装上，高通采取了三种不同的形式：1. DM.2e，15W，超过50 TOPS；2. DM.2，25W，超过200 TOPS；3. PCle，75W，约400 TOPS。其中，DM.2从外形来看，有点像两个相邻的M.2连接器，其中，M.2以尺寸小、传输性能高广受欢迎。  
高通也同时发布了对应的边缘人工智能开发工具包——Cloud AI 100 Edge AI SDK，由以下3大部分构成：Cloud AI 100芯片（低功耗、高性能AI芯片）、骁龙865模块化平台（负责应用&视频处理）、骁龙X55调制解调器及射频系统（5G连接）。除了上述芯片所包含的5G特性、能耗低等特点以外，还支持24个相机同时拍摄分辨率达1920×1080的视频流、每秒25帧的高清视频。从功耗来看，英特尔的Goya可低达100W，但吞吐量只能达到15000左右。  
- [开源 TensorFlow Lite 设备端推荐解决方案 | TensorFlow](https://mp.weixin.qq.com/s/396C195z7V-FL4Mq2LBSxw)  
文档：https://tensorflow.google.cn/lite/models/recommendation/overview  
摘要：TFLite 开源了一个端到端解决方案来解决设备端的推荐任务。演示应用中，集成的历史长度N =10 的 CNN 模型，Pixel 4 手机的推理延迟仅为 0.05ms。
在下一个版本中，将支持多个特征作为表示，并计划设计更高级的用户编码器，例如基于 Transformer 的编码器 (Vaswani, A., et al., 2017)。  
- [OpenCV4.4 CUDA编译与加速全解析 | OpenCV学堂](https://mp.weixin.qq.com/s/IEmuTWxm3TDYAGwkTUkACg)  
摘要：OpenCV4.4中关于CUDA加速的内容主要有两个部分，第一部分是之前OpenCV支持的图像处理与对象检测传统算法的CUDA加速；第二部分是OpenCV4.2版本之后开始支持的针对深度学习卷积神经网络模型的CUDA加速。这些内容都在OpenCV的扩展模块中，想要获取这OpenCV CUDA的支持，必须首先编译OpenCV CUDA相关的模块，这里主要是开展模块以CUDA开头的那些。此外编译的电脑或者PC必须有N卡（英伟达GPU卡），并且按照好了正确版本的驱动与cuDNN支持软件。本文分为两个部分来说明如何在OpenCV中实现CUDA加速，第一部分是实现CUDA支持版本OpenCV编译，第二部分是OpenCV CUDA SDK编程代码演示。  


> 注：个别链接打不开，请点击文末【阅读原文】跳转


## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)


| 2 | 0 | 2 | 0 |
|:---:|:---:|:---:|:---:|
|  |  | [2020-10-21](../embedded-ai-report/2020-10-21.md) | [2020-09-17](../embedded-ai-report/2020-09-17.md) |
| [2020-08-26](../embedded-ai-report/2020-08-26.md) | [2020-08-06](../embedded-ai-report/2020-08-06.md) | [2020-07-18](../embedded-ai-report/2020-07-18.md) | [2020-07-02](../embedded-ai-report/2020-07-02.md) |
| [2020-06-17](../embedded-ai-report/2020-06-17.md) | [2020-06-03](../embedded-ai-report/2020-06-03.md)  | [2020-05-15](../embedded-ai-report/2020-05-15.md) | [2020-04-26](../embedded-ai-report/2020-04-26.md) |  
| [2020-04-04](../embedded-ai-report/2020-04-04.md) | [2020-03-19](../embedded-ai-report/2020-03-19.md) | [2020-03-02](../embedded-ai-report/2020-03-02.md) | [2020-02-16](../embedded-ai-report/2020-02-16.md) |  
| [2020-01-27](../embedded-ai-report/2020-01-27.md) | [2020-01-06](../embedded-ai-report/2020-01-06.md) | [2019-12-17](../embedded-ai-report/2019-12-17.md)  |  [2019-12-02](../embedded-ai-report/2019-12-02.md) |
| 2 | 0 | 1 | 9 |  
| [2019-11-30](../embedded-ai-report/2019-11-30.md) | [2019-11-18](../embedded-ai-report/2019-11-18.md) | [2019-10-31](../embedded-ai-report/2019-10-31.md)  |  [2019-10-17](../embedded-ai-report/2019-10-17.md) |  
| [2019-10-03](../embedded-ai-report/2019-10-03.md) | [2019-09-16](../embedded-ai-report/2019-09-16.md) | [2019-08-30](../embedded-ai-report/2019-08-30.md)  |  [2019-08-15](../embedded-ai-report/2019-08-15.md) |  
| [2019-07-30](../embedded-ai-report/2019-07-30.md) | [2019-07-15](../embedded-ai-report/2019-07-15.md) | [2019-06-29](../embedded-ai-report/2019-06-29.md)  |  [2019-06-17](../embedded-ai-report/2019-06-17.md) |  
| [2019-05-30](../embedded-ai-report/2019-05-30.md) | [2019-05-15](../embedded-ai-report/2019-05-15.md) | [2019-04-27](../embedded-ai-report/2019-04-27.md)  |  [2019-04-13](../embedded-ai-report/2019-04-13.md) |  
| [2019-03-31](../embedded-ai-report/2019-03-31.md) | | |  

----

![wechat_qrcode](../wechat_qrcode.jpg)

> 往期回顾：见公众号主菜单【历史消息】
- WeChat: NeuralTalk  
- Editor: https://github.com/ysh329  
- Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
151.101.56.133
