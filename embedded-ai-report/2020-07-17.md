---
layout: default
---

# 嵌入式AI简报 (2020-07-17)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：本次18条。

先是一些其他热身小新闻：

- 英伟达超英特尔成美国市值最高芯片商；
- 三星电子修改了芯片工艺路线图，原定于2021年量产的三星4nm被跳过，将由5nm直接上升到3nm，原因是为了推进3nm工艺的顺利量产，还有就是与台积电的市场竞争；
- 高通推出骁龙865处理器的升级版—骁龙865Plus，搭载骁龙X55 5G调制解调器，官方称性能提升了10%。865Plus频率突破到了3.1GHz，采用了Kryo 585 CPU和Adreno 650 GPU；
- SA：Q1全球手机处理器市场收益增6％。据Strategy Analytics手机元件技术服务最新发布的研究报告，在公共卫生事件期间，2020年Q1全球智能手机应用处理器市场收益增长了6％，达到47亿美元。高通、海思、苹果、三星LSI和联发科在今年Q1占据了全球智能手机应用处理器市场收益份额的前五名。其中，高通的收益份额占40％，海思占20％，苹果占15％。Strategy Analytics估计，2020年Q1，5G智能手机应用处理器占高通智能手机应用处理器出货总量的20％以上；
- 阿里云IoT、天猫精灵联合成立AIoT创新中心，将整合阿里巴巴包括达摩院在内的技术能力；
- Android 11新增永久专用智能家居控件，谷歌在Android 11中加入了一个永久专用的智能家居控件并与GoogleAssistant打通；  
- 深圳宣布买5G手机每人最高补贴1000元

7月8日，来自深圳新闻网官方微博的消息显示，为了刺激消费，深圳决定买5G手机每人最高补贴1000元。深圳市政府办公厅日前印发《深圳市关于进一步激发消费活力促进消费增长的若干措施》提出，联合生产厂家和家电销售企业实施家电“以旧换新”和智能产品补贴计划，鼓励家电企业发放消费优惠券，对消费者新购笔记本电脑、平板电脑、5G手机、4K和8K电视等智能数码产品和节能家电产品，按实际购买价格的10％给予补贴，每位居民最高补贴1000元。

> 注：个别链接打不开，请点击文末【阅读原文】跳转

## 业界新闻

- [Graphcore发布第二代IPU及IPU-M2000 三大颠覆性技术定义AI计算的未来 | Graphcore](https://mp.weixin.qq.com/s/NiJiHKiU1y6TtY0Luq2evQ)  
摘要：Graphcore发布第二代IPU以及大规模系统级产品IPU-Machine：M2000（IPU-M2000），新一代产品具有更强的处理能力、更多的内存和内置的可扩展性，可处理极其庞大的机器智能工作负载。  
IPU-Machine M2000是即插即用的机器智能计算刀片，其设计易于部署，并支持可大规模扩展的系统。纤巧的1U刀片可提供1 PetaFlop机器智能计算能力，并且包括集成在机箱中的、针对AI横向扩展进行了优化的联网技术。”  
每个IPU-M2000的核心都是我们新的Graphcore Colossus™Mk2 GC200 IPU。该芯片采用台积电最新的7纳米工艺技术开发，每个芯片在一个823平方毫米的裸片上包含超过594亿个晶体管，使其成为有史以来最复杂的处理器。除了FP32 IEEE浮点运算的支持外，还支持FP16.32（16位乘以32位累加）和FP16.16（16位乘法累加）。但独特之处在于，硬件支持随机取整。AI-Float算术块还为稀疏算术浮点运算提供了本机支持。我们为各种稀疏操作提供库支持，包括块稀疏性和动态稀疏性。  
通信层面，专用AI联网IPU-Fabric™可提供低时延和高带宽。每个IPU-M2000均可提供2.8Tbps。当您将越来越多的IPU-M2000机箱连接在一起时，总带宽将增加到每秒许多Petabits。IPU-Fabric使用3D环形拓扑，原因是效率最大化，以及它很好地映射了机器智能计算中并行性的三个维度。  
- [Imagination发布XS GPU：专注汽车行业的终极GPU系列](https://mp.weixin.qq.com/s/g3-rTnp1nEm2rkspvd0gsg)  
摘要：多年来，大家的印象对Imagination Technologies是在移动端领域的知名GPU供应商，但Imagination也为汽车应用处理器市场三大巨头中的两个提供GPU IP，占据了最大的市场份额。
这也是业界首款功能安全GPU产品系列：XS GPU产品系列的工艺制造经过独立验证，并符合ISO 26262标准（汽车行业电子产品安全标准）。
随着专为功能安全而设计的XSGPU产品系列推出，它们可以用于某些以前没有GPU参与的车内任务。这分为两类：一是图形任务，比如在仪表盘或全景环视系统上显示安全相关的信息；二是用于ADAS的计算任务，通常称为“计算”。而我们的GPU非常适用于图形和计算任务（对于后者，我们有专用的神经网络加速器）。  
不管哪种任务，整个运行系统必须功能安全，必须符合ISO 26262标准。旨在确保所有汽车电子器件的安全性，从而降低任何故障产生的影响（即便无法避免故障）。在真实的汽车驾驶中，这意味着如果系统发生某种非灾难性的故障，车辆仍然可以安全停车或直接开到维修中心。这就是所谓的功能安全（FuSa）。  
- [高通骁龙4100系列解析：安卓智能手表的复兴希望 | 三易生活](https://mp.weixin.qq.com/s/XTaKj5G2tiVZOOKu1KKP8Q)  
摘要：上期咱们简报发了有关骁龙4100系列的新闻，这次解析会更深入一些。  
骁龙4100可穿戴平台一口气用上了12nm半导体制程、新的1.7GHz四核A53 CPU、新架构的Adreno 504图形处理器。  
高通设计了两颗Hexagon QDSP6 V56 数字信号处理器（DSP），这并不是为了实现两倍的DSP性能，而是将一颗DSP专门用于处理基带通信和GPS定位，另一颗DSP专门用于服务音频处理和传感器信号整合（Sensor Hub）。这样一来，单个DSP的负载得到减轻、功耗大幅降低的同时，持续定位或是连续健康监测的稳定性也能随之提高。 
骁龙4100平台包含两款不同的硬件方案，即骁龙4100与骁龙4100+。plus版多了一颗基于Cortex-M系列架构的协处理器——QCC1110 Enhanced（直译为增强版）。独立处理器、独立内存和独立DSP的QC1110，其能够在主SoC处于低功耗模式时，独立驱动手表显示65536色的彩色屏幕、能够支撑起持续心率监测、持续睡眠监测，以及持续运动统计等功能继续正常使用。换句话说，有了骁龙4100+，安卓智能手表哪怕还剩下15%的电量，也能以近乎完全的健康和运动功能继续用上不止一天时间，彻底解决了“续航焦虑”问题。  
- [安谋中国“星辰”处理器7个项目已流片 | 今日芯闻](https://mp.weixin.qq.com/s/Jvj3hK2O2nFsd0xkyPPtjw)  
摘要：7月8日，安谋中国举办了“星辰”处理器媒体分享会，Arm中国产品研发副总裁刘澍披露了其首款全自研32位嵌入式处理器IP“星辰（STAR-MC1）”的最新落地进展，它支持了现在的Armv8-M架构里所有的特点和最新的指令扩展。从Arm V6开始到V7架构增强了更多的处理能力，包括SMID和DSP指令扩展以及浮点协处理器扩展。目前“星辰”处理器已经有30多个授权客户，其中有21个客户已经进行项目集成、设计，7个项目已经流片。  
 
https://developer.sony.com/develop/spresense/
Edge computing with low power consumption
The Spresense microcontroller board enables edge solutions with high computing ability and low power consumption.


## 论文

 
- [打破常规，逆残差模块超强改进，新一代移动端模型MobileNeXt来了！精度速度双超MobileNetV2 | 极市平台](https://mp.weixin.qq.com/s/3-Hil8dgT3DZdqnO3iAZFg)  
摘要：依图科技&新加坡国立大学颜水成团队提出的一种对标MobileNetV2的网络架构MobileNeXt。它针对MobileNetV2的核心模块逆残差模块存在的问题进行了深度分析，提出了一种新颖的SandGlass模块，并用于组建了该文的MobileNeXt架构，SandGlass是一种通用的模块，它可以轻易的嵌入到现有网络架构中并提升模型性能。该文应该是近年来为数不多的优秀终端模型了。为更适合于手机端，作者引入了一个新的超参数：identity tensor multiplier，用于减少对精度几乎没有提升的加法操作，并减少访存操作的次数。

## 开源项目

> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [OPEN AI Lab开源嵌入式全场景推理框架Tengine-Lite |  OPEN AI LAB开放智能](https://mp.weixin.qq.com/s/CzqmyCeNiWcseHZlSOMRQg)  
摘要：Tengine-Lite由OPEN AI Lab于7月6日正式开源，该框架特点在于提供了整套便捷的MCU AI开发工具，还为嵌入式AI软件产业建立了开放的开发生态平台。基于纯C代码重新搭建的更简洁、高效、代码可读性更好的Tengine-Lite，可以说将轻量化无依赖做到了极致。Linux版本的库大小在500KB以内，安卓库大小在1MB内；编译极速；框架和计算库分离采用Plug-in设计，也支持其它异构计算库的挂载；相比Tengine，Lite版本在单核、多核的性能稳定性提升明显（见性能散点图略了这里）；嵌入式全场景，FreeRTOS\RTT\Lite-OS等极简的实时操作系统或裸机Bare-matel上运行，还可以在MCU、RISC-V等低功耗、资源极为有限的IoT芯片主控上运行。可用于语音、视觉等多种场景。  
- [PaddlePaddle/PaddleOCR：8.6M超轻量中英文OCR模型开源，训练部署一条龙，Demo在线可玩 | 量子位](https://mp.weixin.qq.com/s/i1Dm18qp93jzWnMoqRU2gA)
项目地址：https://github.com/PaddlePaddle/PaddleOCR
在线Demo：https://www.paddlepaddle.org.cn/hub/scene/ocr
PaddleOCR发布的超轻量模型，主要由4.1M的检测模型和4.5M的识别模型组成。其中，检测模型的Base模型采用DB算法，文本模型的Base模型采用经典的CRNN算法。  
鉴于MobileNetV3在端侧系列模型中的优越表现，两个模型均选择使用MobileNetV3作为骨干网络，可将模型大小初步减少90%以上。此外，还采用减小特征通道数等策略，进一步对模型大小压缩。通用OCR模型的精度可能不能满足需求，还可快速自定义训练。
预测的平台支持方面，除支持X86 CPU、NV和昆仑芯片的原生推理库，也有Paddle-Lite支持手机嵌入式端，包括ARM CPU、GPU、华为NPU、比特大陆、RK NPU、MTK APU、百度昆仑芯片等等。  
- OpenMMLab:香港中文大学-商汤科技联合实验室 MMLab 开源的算法平台，不到两年时间，已经包含众多 SOTA 计算机视觉算法。  
项目主页：http://openmmlab.org/  
OpenMMLab 在Github上不是一个单独项目，除了大家所熟知的 Github 上万 star 目标检测库 MMDetection，还有其他方向的代码库和数据集，非常值得从事计算机视觉研发的朋友关注。  
近期 OpenMMLab 进行了密集更新，新增了多个库，官方称涉及超过 10 个研究方向，开放超过 100 种算法和 600 种预训练模型，目前Github总星标超过 1.7 万。是CV方向系统性较强、社区活跃的开源平台。  
这些库大部分都基于深度学习 PyTorch 框架，算法紧跟前沿，方便易用，文档较为丰富，无论对于研究还是工程开发的朋友都很值得了解。


- [PyTorchLightning/pytorch-lightning：让PyTorch更轻便 | 量子位](https://mp.weixin.qq.com/s/VqUypT_OkAQAD_y-E4msLw)  
摘要：一直以来，PyTorch就以简单又好用的特点，广受AI研究者的喜爱。但是，一旦任务复杂化，就可能会发生一系列错误，花费的时间更长。于是，就诞生了这样一个“友好”的PyTorch Lightning。Lightning将DL/ML代码分为三种类型：研究代码、工程代码、非必要代码。针对不同的代码，Lightning有不同的处理方式。研究代码与工程代码相分离，还将PyTorch代码结构化，更加直观的展现数据操作过程。更易于理解，不易出错，本来很冗长的代码一下子就变得轻便了，对AI研究者十分的友好。  
- [介绍一款NVIDIA Jetson实用功率估算工具：PowerEstimator | 吉浦迅科技](https://mp.weixin.qq.com/s/yajYoWkjNOmaVaYQaJygrQ)  
摘要：PowerEstimator是用于Jetson模块上系统（SOM）的功率估算工具。它估计平均SOM功耗并为系统配置和要建模的目标工作负载生成nvpmodel配置文件。该工具提供了一组输入旋钮，例如时钟频率，活动内核数，负载水平和设备运行状态，用于定义目标工作负载并在将配置应用于目标设备之前获得功耗估算值。
使用PowerEstimator进行以下操作：

1）在开发应用程序之前获取SOM功率估计

2）调整系统资源和参数，并查看它们如何影响SOM的总功耗

3）根据SOM功率估算，获得对散热要求的初步分析

4）生成并下载用于自定义电源模式的nvpmodel配置文件

## 博文

- [我把 ncnn 移植到 RISC-V 啦！ | NeuralTalk](https://mp.weixin.qq.com/s/1Q-Vg9jMT3HRfnQHwVROnw)  
摘要：RISC-V（发音为“risk-five”）是一个基于精简指令集（RISC）原则的开源指令集架构（ISA）。其重要意义，在于设计使其适用于现代计算设备（如仓库规模云计算机、高端移动电话和微小嵌入式系统）。设计者考虑到了这些用途中的性能与功率效率。该指令集还具有众多支持的软件，这解决了新指令集通常的弱点。
本文是 ncnn up如何一步一步让 ncnn 支持 RISC-V 的学习笔记，对很多框架开发者尤其是希望支持 RISC-V 的框架开发者，相信有一定帮助。  
- [ARM编译器如何执行编译和链接操作 | strongerHuang](https://mp.weixin.qq.com/s/FvJjh1fpicMR4ZwCc0m_Xw)  
摘要：ARM处理器在市面上到处都是ARM7、ARM9、Cortex-M、Cortex-R、Cortex-A包含的种类繁多，今天我们就来了解一下ARM代码编译链接的工作流程，以及过程中需要的相关概念信息。  
- [iOS Memory 内存详解 | 一瓜技术](https://mp.weixin.qq.com/s/YpJa3LeTFz9UFOUcs5Bitg)  
摘要：本文以 iOS Memory 的相关内容作为主题，主要从一般操作系统的内存管理、iOS 系统内存、app 内存管理等三个层面进行了介绍。  
iOS 是基于 BSD 发展而来，所以先理解一般的桌面操作系统的内存机制是非常有必要的。在此基础之上，本文会进一步在 iOS 系统层面进行分析，包括 iOS 整体的内存机制，以及 iOS 系统运行时的内存占用的情况。最后会将粒度缩小到 iOS 中的单个 app，讲到单个 app 的内存管理策略。  
- [剖析Conv的几种方式和对应结构及其变种 | AI算法及图像处理](https://mp.weixin.qq.com/s/OTQ0GDmaM7i_34q7oODZFw)  
摘要：概述了高效CNN模型（如MobileNet及其变体）中使用的 blocks及其计算量，在空间和通道域进行卷积的直观说明。  
- [使用OpenVINO部署并加速Pytorch表情识别模型 | OpenCV学堂](https://mp.weixin.qq.com/s/4CwuJp6x4b1zDBSSanDvDA)  
摘要：OpenVINO自带的表情识别模型是Caffe版本的，但这次我们以pytorch基于残差网络结构的全卷积网络作为部署对象。本文将包括如何转换为ONNX模型，再转为OpenVINO的IR，再最终加速推理，得到结果。


> 注：个别链接打不开，请点击文末【阅读原文】跳转



## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)


| 2 | 0 | 2 | 0 |
|:---:|:---:|:---:|:---:|
| - | - | - | [2020-07-02](../embedded-ai-report/2020-07-02.md) |
| [2020-06-17](../embedded-ai-report/2020-06-17.md) | [2020-06-03](../embedded-ai-report/2020-06-03.md)  | [2020-05-15](../embedded-ai-report/2020-05-15.md) | [2020-04-26](../embedded-ai-report/2020-04-26.md) |  
| [2020-04-04](../embedded-ai-report/2020-04-04.md) | [2020-03-19](../embedded-ai-report/2020-03-19.md) | [2020-03-02](../embedded-ai-report/2020-03-02.md) | [2020-02-16](../embedded-ai-report/2020-02-16.md) |  
| [2020-01-27](../embedded-ai-report/2020-01-27.md) | [2020-01-06](../embedded-ai-report/2020-01-06.md) | [2019-12-17](../embedded-ai-report/2019-12-17.md)  |  [2019-12-02](../embedded-ai-report/2019-12-02.md) |
| 2 | 0 | 1 | 9 |  
| [2019-11-30](../embedded-ai-report/2019-11-30.md) | [2019-11-18](../embedded-ai-report/2019-11-18.md) | [2019-10-31](../embedded-ai-report/2019-10-31.md)  |  [2019-10-17](../embedded-ai-report/2019-10-17.md) |  
| [2019-10-03](../embedded-ai-report/2019-10-03.md) | [2019-09-16](../embedded-ai-report/2019-09-16.md) | [2019-08-30](../embedded-ai-report/2019-08-30.md)  |  [2019-08-15](../embedded-ai-report/2019-08-15.md) |  
| [2019-07-30](../embedded-ai-report/2019-07-30.md) | [2019-07-15](../embedded-ai-report/2019-07-15.md) | [2019-06-29](../embedded-ai-report/2019-06-29.md)  |  [2019-06-17](../embedded-ai-report/2019-06-17.md) |  
| [2019-05-30](../embedded-ai-report/2019-05-30.md) | [2019-05-15](../embedded-ai-report/2019-05-15.md) | [2019-04-27](../embedded-ai-report/2019-04-27.md)  |  [2019-04-13](../embedded-ai-report/2019-04-13.md) |  
| [2019-03-31](../embedded-ai-report/2019-03-31.md) | | |  

----

![wechat_qrcode](../wechat_qrcode.jpg)

> 往期回顾：见公众号主菜单【历史消息】
- WeChat: NeuralTalk  
- Editor: https://github.com/ysh329  
- Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
