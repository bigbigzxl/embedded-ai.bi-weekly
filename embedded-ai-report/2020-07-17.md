---
layout: default
---

# 嵌入式AI简报 (2020-07-17)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：本次18条。

先是一些其他热身小新闻：


> 注：个别链接打不开，请点击文末【阅读原文】跳转

## 业界新闻

- [Graphcore发布第二代IPU及IPU-M2000 三大颠覆性技术定义AI计算的未来 | Graphcore](https://mp.weixin.qq.com/s/NiJiHKiU1y6TtY0Luq2evQ)  
摘要：Graphcore发布第二代IPU以及大规模系统级产品IPU-Machine：M2000（IPU-M2000），新一代产品具有更强的处理能力、更多的内存和内置的可扩展性，可处理极其庞大的机器智能工作负载。  
IPU-Machine M2000是即插即用的机器智能计算刀片，其设计易于部署，并支持可大规模扩展的系统。纤巧的1U刀片可提供1 PetaFlop机器智能计算能力，并且包括集成在机箱中的、针对AI横向扩展进行了优化的联网技术。”  
每个IPU-M2000的核心都是我们新的Graphcore Colossus™Mk2 GC200 IPU。该芯片采用台积电最新的7纳米工艺技术开发，每个芯片在一个823平方毫米的裸片上包含超过594亿个晶体管，使其成为有史以来最复杂的处理器。除了FP32 IEEE浮点运算的支持外，还支持FP16.32（16位乘以32位累加）和FP16.16（16位乘法累加）。但独特之处在于，硬件支持随机取整。AI-Float算术块还为稀疏算术浮点运算提供了本机支持。我们为各种稀疏操作提供库支持，包括块稀疏性和动态稀疏性。  
通信层面，专用AI联网IPU-Fabric™可提供低时延和高带宽。每个IPU-M2000均可提供2.8Tbps。当您将越来越多的IPU-M2000机箱连接在一起时，总带宽将增加到每秒许多Petabits。IPU-Fabric使用3D环形拓扑，原因是效率最大化，以及它很好地映射了机器智能计算中并行性的三个维度。  
- [Imagination发布XS GPU：专注汽车行业的终极GPU系列](https://mp.weixin.qq.com/s/g3-rTnp1nEm2rkspvd0gsg)  
摘要：多年来，大家的印象对Imagination Technologies是在移动端领域的知名GPU供应商，但Imagination也为汽车应用处理器市场三大巨头中的两个提供GPU IP，占据了最大的市场份额。
这也是业界首款功能安全GPU产品系列：XS GPU产品系列的工艺制造经过独立验证，并符合ISO 26262标准（汽车行业电子产品安全标准）。
随着专为功能安全而设计的XSGPU产品系列推出，它们可以用于某些以前没有GPU参与的车内任务。这分为两类：一是图形任务，比如在仪表盘或全景环视系统上显示安全相关的信息；二是用于ADAS的计算任务，通常称为“计算”。而我们的GPU非常适用于图形和计算任务（对于后者，我们有专用的神经网络加速器）。  
不管哪种任务，整个运行系统必须功能安全，必须符合ISO 26262标准。旨在确保所有汽车电子器件的安全性，从而降低任何故障产生的影响（即便无法避免故障）。在真实的汽车驾驶中，这意味着如果系统发生某种非灾难性的故障，车辆仍然可以安全停车或直接开到维修中心。这就是所谓的功能安全（FuSa）。  
- [高通骁龙4100系列解析：安卓智能手表的复兴希望 | 三易生活](https://mp.weixin.qq.com/s/XTaKj5G2tiVZOOKu1KKP8Q)  
摘要：上期咱们简报发了有关骁龙4100系列的新闻，这次解析会更深入一些。  
骁龙4100可穿戴平台一口气用上了12nm半导体制程、新的1.7GHz四核A53 CPU、新架构的Adreno 504图形处理器。  
高通设计了两颗Hexagon QDSP6 V56 数字信号处理器（DSP），这并不是为了实现两倍的DSP性能，而是将一颗DSP专门用于处理基带通信和GPS定位，另一颗DSP专门用于服务音频处理和传感器信号整合（Sensor Hub）。这样一来，单个DSP的负载得到减轻、功耗大幅降低的同时，持续定位或是连续健康监测的稳定性也能随之提高。

骁龙4100平台包含两款不同的硬件方案，即骁龙4100与骁龙4100+。plus版多了一颗基于Cortex-M系列架构的协处理器——QCC1110 Enhanced（直译为增强版）。独立处理器、独立内存和独立DSP的QC1110，其能够在主SoC处于低功耗模式时，独立驱动手表显示65536色的彩色屏幕、能够支撑起持续心率监测、持续睡眠监测，以及持续运动统计等功能继续正常使用。换句话说，有了骁龙4100+，安卓智能手表哪怕还剩下15%的电量，也能以近乎完全的健康和运动功能继续用上不止一天时间，彻底解决了“续航焦虑”问题。 


## 论文

 


## 开源项目

> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [OPEN AI Lab开源嵌入式全场景推理框架Tengine-Lite |  OPEN AI LAB开放智能](https://mp.weixin.qq.com/s/CzqmyCeNiWcseHZlSOMRQg)  
摘要：Tengine-Lite由OPEN AI Lab于7月6日正式开源，该框架特点在于提供了整套便捷的MCU AI开发工具，还为嵌入式AI软件产业建立了开放的开发生态平台。基于纯C代码重新搭建的更简洁、高效、代码可读性更好的Tengine-Lite，可以说将轻量化无依赖做到了极致。Linux版本的库大小在500KB以内，安卓库大小在1MB内；编译极速；框架和计算库分离采用Plug-in设计，也支持其它异构计算库的挂载；相比Tengine，Lite版本在单核、多核的性能稳定性提升明显（见性能散点图略了这里）；嵌入式全场景，FreeRTOS\RTT\Lite-OS等极简的实时操作系统或裸机Bare-matel上运行，还可以在MCU、RISC-V等低功耗、资源极为有限的IoT芯片主控上运行。可用于语音、视觉等多种场景。  
- [PyTorchLightning/pytorch-lightning：让PyTorch更轻便 | 量子位](https://mp.weixin.qq.com/s/VqUypT_OkAQAD_y-E4msLw)  
摘要：一直以来，PyTorch就以简单又好用的特点，广受AI研究者的喜爱。但是，一旦任务复杂化，就可能会发生一系列错误，花费的时间更长。于是，就诞生了这样一个“友好”的PyTorch Lightning。Lightning将DL/ML代码分为三种类型：研究代码、工程代码、非必要代码。针对不同的代码，Lightning有不同的处理方式。研究代码与工程代码相分离，还将PyTorch代码结构化，更加直观的展现数据操作过程。更易于理解，不易出错，本来很冗长的代码一下子就变得轻便了，对AI研究者十分的友好。  


## 博文



> 注：个别链接打不开，请点击文末【阅读原文】跳转



## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)


| 2 | 0 | 2 | 0 |
|:---:|:---:|:---:|:---:|
| - | - | - | [2020-07-02](../embedded-ai-report/2020-07-02.md) |
| [2020-06-17](../embedded-ai-report/2020-06-17.md) | [2020-06-03](../embedded-ai-report/2020-06-03.md)  | [2020-05-15](../embedded-ai-report/2020-05-15.md) | [2020-04-26](../embedded-ai-report/2020-04-26.md) |  
| [2020-04-04](../embedded-ai-report/2020-04-04.md) | [2020-03-19](../embedded-ai-report/2020-03-19.md) | [2020-03-02](../embedded-ai-report/2020-03-02.md) | [2020-02-16](../embedded-ai-report/2020-02-16.md) |  
| [2020-01-27](../embedded-ai-report/2020-01-27.md) | [2020-01-06](../embedded-ai-report/2020-01-06.md) | [2019-12-17](../embedded-ai-report/2019-12-17.md)  |  [2019-12-02](../embedded-ai-report/2019-12-02.md) |
| 2 | 0 | 1 | 9 |  
| [2019-11-30](../embedded-ai-report/2019-11-30.md) | [2019-11-18](../embedded-ai-report/2019-11-18.md) | [2019-10-31](../embedded-ai-report/2019-10-31.md)  |  [2019-10-17](../embedded-ai-report/2019-10-17.md) |  
| [2019-10-03](../embedded-ai-report/2019-10-03.md) | [2019-09-16](../embedded-ai-report/2019-09-16.md) | [2019-08-30](../embedded-ai-report/2019-08-30.md)  |  [2019-08-15](../embedded-ai-report/2019-08-15.md) |  
| [2019-07-30](../embedded-ai-report/2019-07-30.md) | [2019-07-15](../embedded-ai-report/2019-07-15.md) | [2019-06-29](../embedded-ai-report/2019-06-29.md)  |  [2019-06-17](../embedded-ai-report/2019-06-17.md) |  
| [2019-05-30](../embedded-ai-report/2019-05-30.md) | [2019-05-15](../embedded-ai-report/2019-05-15.md) | [2019-04-27](../embedded-ai-report/2019-04-27.md)  |  [2019-04-13](../embedded-ai-report/2019-04-13.md) |  
| [2019-03-31](../embedded-ai-report/2019-03-31.md) | | |  

----

![wechat_qrcode](../wechat_qrcode.jpg)

> 往期回顾：见公众号主菜单【历史消息】
- WeChat: NeuralTalk  
- Editor: https://github.com/ysh329  
- Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
