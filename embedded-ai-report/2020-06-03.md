---
layout: default
---

############### 嵌入式AI简报 (2020-06-03)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：

## 业界新闻

- [树莓派4首发8GB版本，售价75刀，还可尝鲜64位操作系统 | 机器之心](https://mp.weixin.qq.com/s/QnaX9_JcBuF4kVSpcD-O7Q)  
摘要：树莓派 4 使用四核 64 位的 ARM Cortex-A72 处理器，具有千兆以太网，双频 802.11ac 无线网，蓝牙 5.0，两个 USB 3.0 和两个 USB 2.0，支持连接两台 4K 显示器，GPU 支持 OpenGL ES 3.x，4K 60fps HEVC 视频硬件解码等。在这如信用卡一般大小的开发板上集成了如此强大的功能，可谓麻雀虽小，五脏俱全。插上 micro-SD 卡，接上鼠标、键盘、显示器就能摇身一变，当成电脑来使用。  
使用 TensorFlow Lite 在同样的数据集上达到普通 TensorFlow 的 3～4 倍。4代的推理速度超过树莓派 3B+ 4 倍以上，性能直逼 Jetson Nano。配合使用 Coral USB 加速棒，速度甚至比 MBP 还快。Jetson Nano Developer Kit 官方标价 99 美元。  
除了深度学习以外，树莓派还能有很多新奇玩法，一个小小的板子，满足了你从 Web 服务器、机器人到 IoT 的各种需求，甚至还可以搭建树莓派集群，运行 K8s等。

- [面向下一代Web的深度学习编译：WebAssembly和WebGPU初探 | 知乎](https://zhuanlan.zhihu.com/p/141008345)  
摘要：虽然目前有很多已有框架（如tensorflowjs, onnxjs)的工作在尝试支持机器学习模型的浏览器部署。在浏览器中运行机器学习始终存在着性能问题。而这个问题的根本原因是因为目前的浏览器端编程模型无法充分利用GPU资源。虽然WebGL允许我们可以通过图形渲染的方式去访问GPU，我们依然无法引入shared memory，generic storage buffer这些计算特有的概念去优化浏览器端的程序（新版本的OpenGL部分解决了这个问题，但是目前WebGL依然还是基于旧的OpenGL标准）。  
当然标准也在不断演化，最近Web端两个重要的新元素-- WebAssembly和WebGPU给了解决浏览器端机器学习一个新的希望。WebGPU是下一代互联网的图形学接口，目前已经进入了实现阶段，主要浏览器的nightly版本已经加入了WebGPU的支持。从API上，WebGPU支持了compute shader，使得更加极致优化浏览器端的算子成为可能。  
为了探索这个可能性，TVM社区最近加入了WebAssembly和WebGPU后端的支持。通过已有的架构生成嵌入WebGPU compute shader的wasm模块。我们在Chrome预览版本上的测试结果展示了很大的潜力 -- tvm生成的WebGPU模块在MacOS上可以获得和直接本地运行native metal几乎一样的效率。



## 论文


- [一篇关于深度学习编译器架构的综述论文 | 知乎](https://zhuanlan.zhihu.com/p/139552817)  
标题：The Deep Learning Compiler: A Comprehensive Survey  
链接：https://arxiv.org/abs/2002.03794  
摘要：目前还都没有全面分析深度学习编译器这种独特设计架构。本文详细剖析常用的设计思想，对现有的深度学习编译器进行全面总结，重点是面向深度学习的多级中间表示（IR）以及前后端的优化。具体来说，作者从各个方面对现有编译器做全面比较，对多级IR的设计进行了详细分析，并介绍了常用的优化技术。最后，文章强调对今后编译器潜在研究方向的一些见解。基本上这是深度学习编译器设计体系结构（不是硬件方面）的第一个综述。  

## 开源项目

> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [mindspore-ai/mindspore:新版本v0.3.0-alpha发布！差分隐私、二阶优化、Pytorch模型支持等六大杀器来袭！ | MindSpore](https://mp.weixin.qq.com/s/5dvKTKgXt1Rl6hdKwWPr2A)  
摘要：暨v0.2.0-alpha版本发布1个月，v0.3.0-alpha按时推出。本次特性包含不限于：
  1. 差分隐私，MindSpore的安全组件提供了差分隐私模块Differential-Privacy，提供支持基于高斯机制的差分隐私优化器（SGD、Momentum），同时还提供差分隐私预算监测器，方便观察差分隐私效果变化。文档：https://www.mindspore.cn/tutorial/zh-CN/0.3.0-alpha/advanced_use/differential_privacy.html；  
  2. 二阶优化，ResNet达到精度（0.759）仅用了42个迭代（epoch），比同软硬件环境的一阶优化快了近1倍（一阶优化使用了81epoch达到目标精度）。文档：https://gitee.com/mindspore/mindspore/tree/r0.3/example/resnet50_imagenet2012_THOR；
  3. 支持Pytorch模型转换。  
除了以上，还新增支持了DeepFM、DeepLabV3、Wide&Deep等新的模型，修复了一些关键bug，增添了网络迁移教程、自定义算子教程等。  
- [matazure/mtensor：同时支持C++和cuda延迟计算的异构计算库 | 极市平台](https://mp.weixin.qq.com/s/3Z_ZvJ7p2z-TqfHwtCp_5Q)  
摘要：mtensor是一个tensor计算库，主要用于多维数组及其计算。其可以结构化高效地在CPU/GPU上实现遍历、滤波、转换等多种操作。也便于数据在CPU与GPU之间的传输交互。mtensor主要特点是延迟计算。  
延迟计算有多种实现方式，最为常见的是eigen所采用的模板表达式。但该种方式每实现一种新的运算就要实现一个完整的模板表达式class且过程繁琐，不易拓展新运算。  
mtensor自研的基于闭包算子的lambda tensor是一种更为通用简洁的延迟计算实现。此外，目前绝大部分支持延迟计算的库都没支持cuda，而对于gpu这种计算能里远强于内存带宽的设备来说延迟计算尤为重要。cuda 9版本以来，cuda C++逐渐完善了对 C++11 和 C++14 的支持，使得cuda的延迟计算可以得到简洁的实现。  


## 博文



## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)


| 2 | 0 | 2 | 0 |
|:---:|:---:|:---:|:---:|
|  |  | [2020-05-15](../embedded-ai-report/2020-05-15.md) | [2020-04-26](../embedded-ai-report/2020-04-26.md) |  
| [2020-04-04](../embedded-ai-report/2020-04-04.md) | [2020-03-19](../embedded-ai-report/2020-03-19.md) | [2020-03-02](../embedded-ai-report/2020-03-02.md) | [2020-02-16](../embedded-ai-report/2020-02-16.md) |  
| [2020-01-27](../embedded-ai-report/2020-01-27.md) | [2020-01-06](../embedded-ai-report/2020-01-06.md) | [2019-12-17](../embedded-ai-report/2019-12-17.md)  |  [2019-12-02](../embedded-ai-report/2019-12-02.md) |
| 2 | 0 | 1 | 9 |  
| [2019-11-30](../embedded-ai-report/2019-11-30.md) | [2019-11-18](../embedded-ai-report/2019-11-18.md) | [2019-10-31](../embedded-ai-report/2019-10-31.md)  |  [2019-10-17](../embedded-ai-report/2019-10-17.md) |  
| [2019-10-03](../embedded-ai-report/2019-10-03.md) | [2019-09-16](../embedded-ai-report/2019-09-16.md) | [2019-08-30](../embedded-ai-report/2019-08-30.md)  |  [2019-08-15](../embedded-ai-report/2019-08-15.md) |  
| [2019-07-30](../embedded-ai-report/2019-07-30.md) | [2019-07-15](../embedded-ai-report/2019-07-15.md) | [2019-06-29](../embedded-ai-report/2019-06-29.md)  |  [2019-06-17](../embedded-ai-report/2019-06-17.md) |  
| [2019-05-30](../embedded-ai-report/2019-05-30.md) | [2019-05-15](../embedded-ai-report/2019-05-15.md) | [2019-04-27](../embedded-ai-report/2019-04-27.md)  |  [2019-04-13](../embedded-ai-report/2019-04-13.md) |  
| [2019-03-31](../embedded-ai-report/2019-03-31.md) | | |  

----

![wechat_qrcode](../wechat_qrcode.jpg)

> 往期回顾：见公众号主菜单【历史消息】
- WeChat: NeuralTalk  
- Editor: https://github.com/ysh329  
- Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
