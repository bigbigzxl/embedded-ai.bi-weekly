---
layout: default
---

# 嵌入式AI简报 (2020-05-13)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：

- Imagination已经将IMG A系列GPU在多个市场中授权给了客户，首批搭载该IP的SoC器件将在今年供货；
- [三星Exynos992曝光6nm制程可能超越骁龙865 | 三易生活](https://mp.weixin.qq.com/s/DQ2aRx276KFUXFYGvHaMig)；
- [高通与Imagination同时宣布支持Google的Android GPU Inspector在各家的Adreno或PowerVR GPU上的负载分析 | Imagination Tech](https://mp.weixin.qq.com/s/sgPyQjLModuvpa8jLh352Q)；
- [小米也迎来高通Adreno GPU驱动更新 | Qualcomm中国](https://mp.weixin.qq.com/s/cGezbnF8O-whKjpkMbl-bw)；  
- [荣耀发布Play 4T新机，搭载中芯国际14nm代工的麒麟710A，且已成功量产 | 安兔兔](https://mp.weixin.qq.com/s/DncvhgPYRAld-jcvK_WLoQ)。  

## 业界新闻


- [OpenCL 3.0 release发布：更灵活、异步DMA扩展支持 | khronos.org](https://www.khronos.org/opencl/)  
摘要：OpenCL 3.0 realigns the OpenCL roadmap to enable developer-requested functionality to be broadly deployed by hardware vendors, and it significantly increases deployment flexibility by empowering conformant OpenCL implementations to focus on functionality relevant to their target markets. OpenCL 3.0 also integrates subgroup functionality into the core specification, ships with a new OpenCL C 3.0 language specification, uses a new unified specification format, and introduces extensions for asynchronous data copies to enable a new class of embedded processors. The provisional OpenCL 3.0 specifications enable the developer community to provide feedback before the specifications and conformance tests are finalized.  
- [Redmi K30 5G首发高通全新SoC 768G | 迷你手机网](https://www.netded.com/news/2020/051150357.html)  
摘要：从命名上看，骁龙768G是骁龙765G的升级版，应该类似于骁龙855和骁龙855+的关系。  
根据爆料，骁龙768G处理器采用了1+1+4（2.8GHz+2.4GHz+1.8GHz）组合，GPU为Adreno 620，骁龙768G的2颗大核A76都提升了主频，GPU主频提升到了750MHz，整体性能提升在10%~15%。据测试安兔兔跑分达到了36万分。  
并且骁龙768G采用7nm EUV工艺制程，是一款集成式双模5G SoC，CPU部分拥有两颗A76架构性能大核，相较骁龙765G，其主频部分提升到了2.8GHz，同时，骁龙768G的GPU频率也提升到了750MHz。  
- [高通骁龙875性能规格曝光！或集成X60 5G基带，台积电5nm工艺 | 智东西](https://mp.weixin.qq.com/s/3tLjsPUHjsQSGbtEcK75tQ)  
摘要：高通即将推出的骁龙875，将采用台积电5nm工艺制造，预计2021年正式发布。此外，该芯片组的规格代号为SM8350，其上一代骁龙865代号则为SM8250。但目前尚不清楚的是，骁龙875芯片的5G调制解调器是否采用集成式方案。  
性能方面，骁龙875采用基于Armv8 Cortex架构的Kryo 685 CPU，Adreno 660 GPU、Adreno 665 VPU和Adreno 1095 DPU，以及一颗Spectra 580图像处理引擎，支持3G/4G/5G调制解调器mmWave（毫米波）和低于6GHz频段。  
- [联发科天玑1000+升级亮相，这次真不用再等了 | 三易生活](https://mp.weixin.qq.com/s/M6rm5rYER9U7idAD3ix1qQ)  
摘要：在GPU性能方面，天玑1000+这次很显然在天玑1000的基础上又进行了增强，因为它将屏幕高帧率显示的上限从此前的120Hz提升到了144Hz，新的“ＭiraVision 画质引擎”可以实现独立AI处理单元（联发科叫APU）和专用画质处理电路的联动计算，直接支持到了4K分辨率视频的AI实时处理。无论是从5G、AI、GPU设计这些“底子”上的技术水准，还是从游戏与视频优化这些“面子”上锦上添花的功能来说，联发科的天玑1000+这次都算是更上了一层楼。  

- [TFRT：全新的 TensorFlow 运行时 | TensorFlow](https://mp.weixin.qq.com/s/62Eaa5iF6mH4N6eW4liAzg)  
摘要：新的 TensorFlow 运行时 — TFRT。TensorFlow RunTime (TFRT) 旨在提供一个统一、可扩展的基础架构层，在各种领域特定硬件上实现一流性能。高效利用多线程主机的 CPU，支持完全异步的编程模型，同时专注于底层效率。   
现有 TensorFlow 的设计初衷是针对图执行和训练工作负载搭建，而新运行时则首要关注即时执行和推理，同时注重架构可扩展性和模块化。更具体地说，TFRT 已实现以下设计亮点：
  1. 为提升性能，TFRT 配备无锁计算图执行器，支持并行操作执行，且同步开销较低。此外，其还配备一个轻量的即时算子分发栈，便于异步即时 API 调用和提高效率；  
  2. 为了更加轻松地扩展 TF 技术栈，我们已将设备运行时与主机运行时（即驱动主机 CPU 和 I/O 工作的核心 TFRT 组件）解耦；  
  3. 为确保行为一致，TFRT 在即时和图执行模式中均使用通用抽象，例如形状函数和内核。  
TFRT 还与 MLIR 紧密集成。例如：  
  1. TFRT 利用 MLIR 的编译器基础架构，为特定目标的运行时执行计算图生成优化表征；
  2. TFRT 使用 MLIR 的可扩展类型系统支持运行时中的任意 C++ 类型，消除了仅支持特定张量的限制。  
https://github.com/tensorflow/runtime  
[如何评价TensorFlow开源的新运行时TFRT | 知乎](https://www.zhihu.com/question/391811802)  


## 论文

- [性能不打折，内存占用减少90%，Facebook提出极致模型压缩方法Quant-Noise
https://mp.weixin.qq.com/s/XwKuIryP1XXNEidZBDlTaQ


## 开源项目

> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [开源一年，阿里轻量级AI推理引擎MNN 1.0.0正式发布 | AI科技大本营](https://mp.weixin.qq.com/s/VBE54nbPn8zmvh6l1UZaag)  
摘要：MNN在阿里巴巴集团内部得到广泛推广，覆盖了如手机淘宝、天猫、优酷、钉钉、闲鱼等20多个App。
新增模型训练的支持，从此MNN不再是单纯的推理引擎，可Quantization Aware Training (QAT)。

利用ARMv8.2指令集，获得了两倍的性能提升。
进一步完善Python工具链，累计新增超过150个接口。
开源了应用层开箱即用的解决方案MNNKit，包含了人脸跟踪与检测、人像分割、手势识别等。

推荐一款纳秒级的C++日志Nanolog - 知乎
https://zhuanlan.zhihu.com/p/136208506

## 博文


- [深度解析MegEngine亚线性显存优化技术 | 旷视研究院](https://mp.weixin.qq.com/s/N-bjcUEF4cQbH5vT0RM9CA)  
摘要：深度学习框架有几种降低显存占用的常用方法，其示例如下：
  1. 通过合适的梯度定义，让算子的梯度计算不再依赖于前向计算作为输入，从而in-place地完成算子的前向计算，比如Sigmoid、Relu等；
  2. 在生命周期没有重叠的算子之间共享显存；
  3. 通过额外的计算减少显存占用，比如利用梯度检查点重新计算中间结果的亚线性显存优化方法[1]；
  4. 通过额外的数据传输减少显存占用，比如把暂时不用的数据从GPU交换到CPU，需要时再从CPU交换回来。  
上述显存优化技术在MegEngine中皆有不同程度的实现，这里重点讨论基于梯度检查点的亚线性显存优化技术。
此外，亚线性优化方法采用简单的网格搜索（grid search）选择检查点，MegEngine在此基础上增加遗传算法，采用边界移动、块合并、块分裂等策略，实现更细粒度的优化，进一步降低了显存占用。

- [一篇关于深度学习编译器架构的综述论文 | 知乎](https://zhuanlan.zhihu.com/p/139552817)  
摘要：目前还都没有全面分析深度学习编译器这种独特设计架构。本文详细剖析常用的设计思想，对现有的深度学习编译器进行全面总结，重点是面向深度学习的多级中间表示（IR）以及前后端的优化。具体来说，作者从各个方面对现有编译器做全面比较，对多级IR的设计进行了详细分析，并介绍了常用的优化技术。最后，文章强调对今后编译器潜在研究方向的一些见解。基本上这是深度学习编译器设计体系结构（不是硬件方面）的第一个综述。  
- [矩阵压缩方法总览 | TensorFlow](https://mp.weixin.qq.com/s/YFRXKBguoYwYXuRLO-yJNA)  
摘要：手机设备的存储空间、算力和电池容量都较低，所以要将模型应用其中就往往需要“偷工减料”，如限制词汇量或牺牲模型质量。因此，压缩模型的不同层中的矩阵将十分有用。主流的矩阵压缩技术包括 剪枝、低秩逼近、量化 和 随机投影。我们认为，大多数这类方法都可看作是通过某种类型的因子分解算法将矩阵分解为两个因子。  

- [借助深度学习模型优化，解锁Arm微控制器上的人工智能
Arm智联未来

https://mp.weixin.qq.com/s/ZsuN6ZYATYen4q8YvWU0Fw

- [FLOPs与模型推理速度 | 知乎](https://zhuanlan.zhihu.com/p/122943688)  
摘要：

- [多Die封装：Chiplet小芯片的研究报告 | 企业存储技术](https://mp.weixin.qq.com/s/IsHItdTYnnDL7KGlVwlA6w)  
- [实现 iPhone 和 iPad 上的更快推理：TensorFlow Lite Core ML Delegate | TensorFlow](https://mp.weixin.qq.com/s/b9iUiWTR2P87aI8YfrFx6A)  
摘要：TensorFlow Lite 面向 GPU、DSP 和/或 NPU 等加速器提供了部分或整套模型推理的 Delegate 选项，旨在实现高效的移动推理。在 Android 上，有几种 Delegate 可供选择：NNAPI、GPU 及最近添加的 Hexagon delegate。此前，Apple 的移动设备 iPhone 和 iPad 上仅可使用 GPU delegate。  
Apple 发布机器学习框架 Core ML 和 Neural Engine（Apple Bionic SoC 中的一种神经处理单元 (NPU)）后，TensorFlow Lite 也可利用 Apple 的硬件。  
此外，神经处理单元 (Neural processing units, NPU) 与 Google 的 Edge TPU 和 Apple 的 Neural Engine 类似，是专为加速机器学习应用而设计的硬件加速器。这类芯片用于加速移动或边缘设备上的模型推理，与在 CPU 或 GPU 上运行推理相比，功耗更低。使用 Neural Engine 及 Apple 的 Core ML API 让浮点模型可以更快速地在 iPhone 和 iPad 上运行。借助它 ，MobileNet 和 Inception V3 等模型能够实现高达 14 倍的性能提升。  
- [400 fps！CenterFace+TensorRT部署人脸和关键点检测 | 我爱计算机视觉](https://mp.weixin.qq.com/s/nvM4YFemXWLTXsPWGNR5Vw)  
摘要：Centerface具有具有小巧精度高特点，是目前最快的人脸检测和关键点的方法。该网络采用了anchor-free的方法，并引入了FPN的结构和思想，使得模型在小尺度的脸上具有更好的鲁棒性。本文也是CenterFace原作者手把手教程。  


## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)

| 2 | 0 | 2 | 0 |
|:---:|:---:|:---:|:---:|
|  |  |  | [2020-04-26](../embedded-ai-report/2020-04-26.md) |  
| [2020-04-04](../embedded-ai-report/2020-04-04.md) | [2020-03-19](../embedded-ai-report/2020-03-19.md) | [2020-03-02](../embedded-ai-report/2020-03-02.md) | [2020-02-16](../embedded-ai-report/2020-02-16.md) |  
| [2020-01-27](../embedded-ai-report/2020-01-27.md) | [2020-01-06](../embedded-ai-report/2020-01-06.md) | [2019-12-17](../embedded-ai-report/2019-12-17.md)  |  [2019-12-02](../embedded-ai-report/2019-12-02.md) |
| 2 | 0 | 1 | 9 |  
| [2019-11-30](../embedded-ai-report/2019-11-30.md) | [2019-11-18](../embedded-ai-report/2019-11-18.md) | [2019-10-31](../embedded-ai-report/2019-10-31.md)  |  [2019-10-17](../embedded-ai-report/2019-10-17.md) |  
| [2019-10-03](../embedded-ai-report/2019-10-03.md) | [2019-09-16](../embedded-ai-report/2019-09-16.md) | [2019-08-30](../embedded-ai-report/2019-08-30.md)  |  [2019-08-15](../embedded-ai-report/2019-08-15.md) |  
| [2019-07-30](../embedded-ai-report/2019-07-30.md) | [2019-07-15](../embedded-ai-report/2019-07-15.md) | [2019-06-29](../embedded-ai-report/2019-06-29.md)  |  [2019-06-17](../embedded-ai-report/2019-06-17.md) |  
| [2019-05-30](../embedded-ai-report/2019-05-30.md) | [2019-05-15](../embedded-ai-report/2019-05-15.md) | [2019-04-27](../embedded-ai-report/2019-04-27.md)  |  [2019-04-13](../embedded-ai-report/2019-04-13.md) |  
| [2019-03-31](../embedded-ai-report/2019-03-31.md) | | |  

----

![wechat_qrcode](../wechat_qrcode.jpg)

> 往期回顾：见公众号主菜单【历史消息】
- WeChat: NeuralTalk  
- Editor: https://github.com/ysh329  
- Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
