---
layout: default
---

# 嵌入式AI简报 (2020-05-13)

**关注模型压缩、低比特量化、移动端推理加速优化、部署**  

> 导读：近来，手机SOC方面，[三星Exynos992曝光6nm制程可能超越骁龙865](https://mp.weixin.qq.com/s/DQ2aRx276KFUXFYGvHaMig)，Imagination新闻频频，Imagination已经将IMG A系列GPU在多个市场中授权给了客户，首批搭载该IP的SoC器件将在今年供货，[高通与Imagination同时宣布支持Google的Android GPU Inspector在各家的Adreno或PowerVR GPU上的负载分析](https://mp.weixin.qq.com/s/sgPyQjLModuvpa8jLh352Q)，[小米迎来高通Adreno GPU驱动更新 | Qualcomm中国](https://mp.weixin.qq.com/s/cGezbnF8O-whKjpkMbl-bw)，[荣耀发布Play 4T新机，搭载中芯国际14nm代工的麒麟710A，且已成功量产](https://mp.weixin.qq.com/s/DncvhgPYRAld-jcvK_WLoQ)。  

## 业界新闻

- [Redmi K30 5G首发高通全新SoC 768G | 迷你手机网](https://www.netded.com/news/2020/051150357.html)  
摘要：从命名上看，骁龙768G是骁龙765G的升级版，应该类似于骁龙855和骁龙855+的关系。  
根据爆料，骁龙768G处理器采用了1+1+4（2.8GHz+2.4GHz+1.8GHz）组合，GPU为Adreno 620，骁龙768G的2颗大核A76都提升了主频，GPU主频提升到了750MHz，整体性能提升在10%~15%。据测试安兔兔跑分达到了36万分。  
并且骁龙768G采用7nm EUV工艺制程，是一款集成式双模5G SoC，CPU部分拥有两颗A76架构性能大核，相较骁龙765G，其主频部分提升到了2.8GHz，同时，骁龙768G的GPU频率也提升到了750MHz。  
- [高通骁龙875性能规格曝光！或集成X60 5G基带，台积电5nm工艺 | 智东西](https://mp.weixin.qq.com/s/3tLjsPUHjsQSGbtEcK75tQ)  
摘要：高通即将推出的骁龙875，将采用台积电5nm工艺预计2021年发布。此外，该芯片组规格代号为SM8350，其上一代骁龙865代号为SM8250。目前不清楚骁龙875芯片的5G调制解调器是否采用集成式方案。  
性能方面，骁龙875采用Armv8 Cortex架构的Kryo 685 CPU，Adreno 660 GPU、Adreno 665 VPU和Adreno 1095 DPU，以及一颗Spectra 580图像处理引擎，支持3G/4G/5G调制解调器mmWave（毫米波）和低于6GHz频段。  
- [联发科天玑1000+升级亮相，这次真不用再等了 | 三易生活](https://mp.weixin.qq.com/s/M6rm5rYER9U7idAD3ix1qQ)  
摘要：GPU性能方面，天玑1000+在天玑1000的基础上增强，将屏幕高帧率显示的上限从120Hz提升到144Hz，新的“ＭiraVision 画质引擎”可实现独立AI处理单元（联发科叫APU）和专用画质处理电路的联动计算，支持4K分辨率视频的AI实时处理。无论是从5G、AI、GPU设计这些“底子”上的技术水准，还是从游戏与视频优化这些“面子”上锦上添花的功能来说，联发科的天玑1000+这次都算是更上了一层楼。  


## 论文

- [一篇关于深度学习编译器架构的综述论文 | 知乎](https://zhuanlan.zhihu.com/p/139552817)  
摘要：目前还都没有全面分析深度学习编译器这种独特设计架构。本文详细剖析常用的设计思想，对现有的深度学习编译器进行全面总结，重点是面向深度学习的多级中间表示（IR）以及前后端的优化。具体来说，作者从各个方面对现有编译器做全面比较，对多级IR的设计进行了详细分析，并介绍了常用的优化技术。最后，文章强调对今后编译器潜在研究方向的一些见解。基本上这是深度学习编译器设计体系结构（不是硬件方面）的第一个综述。  
- [性能不打折，内存占用减少90%，Facebook提出极致模型压缩方法Quant-Noise | 机器之心](https://mp.weixin.qq.com/s/XwKuIryP1XXNEidZBDlTaQ)  
摘要：


## 开源项目

> 注：每条内容前缀为github地址的仓库拥有者和仓库名，补全地址后为`github.com/<repo_owner>/<repo_name>`。

- [alibaba/MNN: 开源一年，阿里轻量级AI推理引擎MNN 1.0.0正式发布 | AI科技大本营](https://mp.weixin.qq.com/s/VBE54nbPn8zmvh6l1UZaag)  
摘要：MNN在阿里巴巴集团内部得到广泛推广，覆盖了如手机淘宝、天猫、优酷、钉钉、闲鱼等20多个App。在这次release中，包括且不限于以下特点：
  1. 新增模型训练的支持，从此MNN不再是单纯的推理引擎，可Quantization Aware Training (QAT)；
  2. 利用ARMv8.2指令集，获得了两倍的性能提升；
  3. 进一步完善Python工具链，累计新增超过150个接口；
  4. 开源了应用层开箱即用的解决方案MNNKit，包含了人脸跟踪与检测、人像分割、手势识别等。
- [OpenCL 3.0 release发布：更灵活、异步DMA扩展支持 | khronos.org](https://www.khronos.org/opencl/)  
摘要：OpenCL 3.0 integrates subgroup functionality into the core specification, ships with a new OpenCL C 3.0 language specification, uses a new unified specification format, and introduces extensions for asynchronous data copies to enable a new class of embedded processors. The provisional OpenCL 3.0 specifications enable the developer community to provide feedback before the specifications and conformance tests are finalized.  
[更多，见如何评价 OpenCL 3.0 | 知乎](https://www.zhihu.com/question/391599659)  
- [tensorflow/runtime:全新的 TensorFlow 运行时 | TensorFlow](https://mp.weixin.qq.com/s/62Eaa5iF6mH4N6eW4liAzg)  
摘要：TensorFlow RunTime (TFRT) 旨在提供一个统一、可扩展的基础架构层，在各种领域特定硬件上实现一流性能。高效利用多线程主机的 CPU，支持完全异步的编程模型，同时专注于底层效率。   
现有 TensorFlow 的设计初衷是针对图执行和训练工作负载搭建，而新运行时则首要关注即时执行和推理，同时注重架构可扩展性和模块化。更具体地说，TFRT 已实现以下设计亮点：
  1. 为提升性能，TFRT 配备无锁计算图执行器，支持并行操作执行，且同步开销较低。此外，其还配备一个轻量的即时算子分发栈，便于异步即时 API 调用和提高效率；  
  2. 为了更加轻松地扩展 TF 技术栈，我们已将设备运行时与主机运行时（即驱动主机 CPU 和 I/O 工作的核心 TFRT 组件）解耦；  
  3. 为确保行为一致，TFRT 在即时和图执行模式中均使用通用抽象，例如形状函数和内核。  
TFRT 还与 MLIR 紧密集成。例如：  
  1. TFRT 利用 MLIR 的编译器基础架构，为特定目标的运行时执行计算图生成优化表征；
  2. TFRT 使用 MLIR 的可扩展类型系统支持运行时中的任意 C++ 类型，消除了仅支持特定张量的限制。  
https://github.com/tensorflow/runtime  
[更多，见如何评价TensorFlow开源的新运行时TFRT | 知乎](https://www.zhihu.com/question/391811802)  
- [NervanaSystems/maxas:矩阵相乘在GPU上的终极优化：深度解析Maxas汇编器工作原理
机器之心
https://mp.weixin.qq.com/s/OYSzol-vufiKPuU9YxtbuA

在从事深度学习框架的实现工作时，了解到 Nervana 有一个称为 Maxas 的汇编代码生成器项目，可以生成性能超过 nVidia 官方版本的矩阵相乘的 GPU 机器码，由此对其工作原理产生兴趣。

项目地址：https://github.com/NervanaSystems/maxas

其作者 Scott Gray 在代码外提供了详细的文档（https://github.com/NervanaSystems/maxas/wiki/SGEMM），但由于该算法的复杂性，行文晦涩，逻辑跳跃，尤其是对一些方法的动机没有交待，很容易迷失在细节中。

本文可以看作按作者对该文档的理解进行的重写，但求在细节上不厌其烦，对其代码的前因后果作尽可能完整的交待，不过大体结构还是按照 maxas 文档来安排，文中图片也全部出自该文档。

## 博文


- [深度解析MegEngine亚线性显存优化技术 | 旷视研究院](https://mp.weixin.qq.com/s/N-bjcUEF4cQbH5vT0RM9CA)  
摘要：深度学习框架有几种降低显存占用的常用方法，其示例如下：
  1. 通过合适的梯度定义，让算子的梯度计算不再依赖于前向计算作为输入，从而in-place地完成算子的前向计算，比如Sigmoid、Relu等；
  2. 在生命周期没有重叠的算子之间共享显存；
  3. 通过额外的计算减少显存占用，比如利用梯度检查点重新计算中间结果的亚线性显存优化方法[1]；
  4. 通过额外的数据传输减少显存占用，比如把暂时不用的数据从GPU交换到CPU，需要时再从CPU交换回来。  
上述显存优化技术在MegEngine中皆有不同程度的实现，这里重点讨论基于梯度检查点的亚线性显存优化技术。
此外，亚线性优化方法采用简单的网格搜索（grid search）选择检查点，MegEngine在此基础上增加遗传算法，采用边界移动、块合并、块分裂等策略，实现更细粒度的优化，进一步降低了显存占用。  
- [矩阵压缩方法总览 | TensorFlow](https://mp.weixin.qq.com/s/YFRXKBguoYwYXuRLO-yJNA)  
摘要：手机设备的存储空间、算力和电池容量都较低，所以要将模型应用其中就往往需要“偷工减料”，如限制词汇量或牺牲模型质量。因此，压缩模型的不同层中的矩阵将十分有用。主流的矩阵压缩技术包括 剪枝、低秩逼近、量化 和 随机投影。我们认为，大多数这类方法都可看作是通过某种类型的因子分解算法将矩阵分解为两个因子。  

- [借助深度学习模型优化，解锁Arm微控制器上的人工智能 | Arm智联未来](https://mp.weixin.qq.com/s/ZsuN6ZYATYen4q8YvWU0Fw)  
摘要：这篇估计是arm生态伙伴的cortex m系列的产品PR文章。DeepLite可针对DNN模型的自动化、按钮优化过程打破模式。用户只需基于预训练的模型、数据集和一些约束(模型大小或精度)，然后点击“Run”。内部软件引擎基于设计空间探索算法，高效地聚合并找到针对其部署的特定约束进行优化的新模型架构。  
DeepLite可以与Pytorch、TensorFlow和ONNX等AI框架以及Arm NN和CMSIS-NN等较底层的工具互操作。自然是利用Arm Cortex-M4等硬件在边缘执行AI任务，通过模型优化与Arm的低功耗硬件(如Cortex-M3、M4或M55)相结合，用户可以在吞吐量和节能方面得到前所未有的提升。  
- [FLOPs与模型推理速度 | 知乎](https://zhuanlan.zhihu.com/p/122943688)  
摘要：两个layer的FLOPs和参数量完全相同。但是推理速度方面，depthwise卷积要远远慢于普通卷积。其原因就是访存数据量的不同：  
由于卷积计算本身已经是flatten的，不需要考虑重复读取问题，那么总共读取的数据量就是feature的大小加上卷积核weight的大小，对于普通卷积来说，总读取数据量为：`100*56*56 + 3*3*100*100 = 4.0e+05`。类似的，depthwise卷积读取的数据总量为：`56*56*10000 + 3*3*10000 = 3.1e+07`。  
可以看到，在同等FLOPs的情况下，depthwise卷积对应的feature size比普通卷积大的多，受制于GPU访存带宽，过高的数据读取与写入量就成为了限制推理速度的瓶颈。  
- [多Die封装：Chiplet小芯片的研究报告 | 企业存储技术](https://mp.weixin.qq.com/s/IsHItdTYnnDL7KGlVwlA6w)  
- [400fps！用TensorRT部署CenterFace做人脸和关键点检测 | 我爱计算机视觉](https://mp.weixin.qq.com/s/nvM4YFemXWLTXsPWGNR5Vw)  
摘要：Centerface小巧精度高，是目前最快的人脸检测和关键点方法。采用anchor-free方法并引入FPN结构，使得模型在小人脸上鲁棒性更好。本文也是CenterFace原作者手把手教程。  


## [往期回顾](https://github.com/ysh329/awesome-embedded-ai)

| 2 | 0 | 2 | 0 |
|:---:|:---:|:---:|:---:|
|  |  |  | [2020-04-26](../embedded-ai-report/2020-04-26.md) |  
| [2020-04-04](../embedded-ai-report/2020-04-04.md) | [2020-03-19](../embedded-ai-report/2020-03-19.md) | [2020-03-02](../embedded-ai-report/2020-03-02.md) | [2020-02-16](../embedded-ai-report/2020-02-16.md) |  
| [2020-01-27](../embedded-ai-report/2020-01-27.md) | [2020-01-06](../embedded-ai-report/2020-01-06.md) | [2019-12-17](../embedded-ai-report/2019-12-17.md)  |  [2019-12-02](../embedded-ai-report/2019-12-02.md) |
| 2 | 0 | 1 | 9 |  
| [2019-11-30](../embedded-ai-report/2019-11-30.md) | [2019-11-18](../embedded-ai-report/2019-11-18.md) | [2019-10-31](../embedded-ai-report/2019-10-31.md)  |  [2019-10-17](../embedded-ai-report/2019-10-17.md) |  
| [2019-10-03](../embedded-ai-report/2019-10-03.md) | [2019-09-16](../embedded-ai-report/2019-09-16.md) | [2019-08-30](../embedded-ai-report/2019-08-30.md)  |  [2019-08-15](../embedded-ai-report/2019-08-15.md) |  
| [2019-07-30](../embedded-ai-report/2019-07-30.md) | [2019-07-15](../embedded-ai-report/2019-07-15.md) | [2019-06-29](../embedded-ai-report/2019-06-29.md)  |  [2019-06-17](../embedded-ai-report/2019-06-17.md) |  
| [2019-05-30](../embedded-ai-report/2019-05-30.md) | [2019-05-15](../embedded-ai-report/2019-05-15.md) | [2019-04-27](../embedded-ai-report/2019-04-27.md)  |  [2019-04-13](../embedded-ai-report/2019-04-13.md) |  
| [2019-03-31](../embedded-ai-report/2019-03-31.md) | | |  

----

![wechat_qrcode](../wechat_qrcode.jpg)

> 往期回顾：见公众号主菜单【历史消息】
- WeChat: NeuralTalk  
- Editor: https://github.com/ysh329  
- Project: https://github.com/ysh329/awesome-embedded-ai  

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">知识共享署名-相同方式共享 4.0 通用许可协议</a>进行许可。
